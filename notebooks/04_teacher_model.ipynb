{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5a3f1d42",
      "metadata": {},
      "source": [
        "# 04 - Teacher Model Testing\n",
        "\n",
        "## Objectives\n",
        "1. Load and test the teacher model `google/flan-t5-xl`\n",
        "2. Verify soft logits (probabilities) generation\n",
        "3. Test teacher inference on NLI examples\n",
        "4. Verify teacher-student integration for distillation\n",
        "\n",
        "## Distillation Flow\n",
        "```\n",
        "Dataset → Teacher Model → Soft Logits (probabilities)\n",
        "       ↘                ↗\n",
        "         Student Model\n",
        "``` \n",
        "```       \n",
        "Loss = α·CE(student, labels) + β·KL(student||teacher)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef2b1c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Check device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da03e788",
      "metadata": {},
      "source": [
        "## 1. Loading the Teacher Model\n",
        "\n",
        "Loading FLAN-T5-XL as the teacher model. The model has ~3B parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd1cc645",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.models.teacher import FlanT5Teacher, TeacherConfig\n",
        "\n",
        "# Teacher configuration\n",
        "teacher_config = TeacherConfig(\n",
        "    model_name=\"google/flan-t5-xl\", # Large teacher model for maximum knowledge distillation\n",
        "    device=device, \n",
        "    use_fp16=True if device == \"cuda\" else False\n",
        ")\n",
        "\n",
        "print(\"Loading teacher model...\")\n",
        "print(f\"Model: {teacher_config.model_name}\")\n",
        "print(f\"Device: {teacher_config.device}\")\n",
        "print(f\"FP16: {teacher_config.use_fp16}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c34434a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carica il teacher model\n",
        "teacher = FlanT5Teacher(teacher_config) # Initialize the teacher model\n",
        "\n",
        "print(f\"\\nTeacher model loaded!\")\n",
        "print(f\"Parameters: {teacher.count_parameters():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f236cc2a",
      "metadata": {},
      "source": [
        "## 2. Inference Testing of the Teacher\n",
        "\n",
        "Testing the teacher on some NLI examples to verify it works correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad77456f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examples of NLI test cases\n",
        "test_examples = [\n",
        "    {\n",
        "        \"premise\": \"A man is playing guitar on stage.\",\n",
        "        \"hypothesis\": \"A person is performing music.\",\n",
        "        \"expected_label\": \"entailment\"\n",
        "    },\n",
        "    {\n",
        "        \"premise\": \"The cat is sleeping on the couch.\",\n",
        "        \"hypothesis\": \"The cat is running outside.\",\n",
        "        \"expected_label\": \"contradiction\"\n",
        "    },\n",
        "    {\n",
        "        \"premise\": \"Children are playing in the park.\",\n",
        "        \"hypothesis\": \"The children are wearing hats.\",\n",
        "        \"expected_label\": \"neutral\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Format as NLI prompt\n",
        "def format_nli_prompt(premise, hypothesis):\n",
        "    return f\"Premise: {premise}\\nHypothesis: {hypothesis}\\nDoes the premise entail, contradict, or is neutral to the hypothesis? Explain your reasoning.\"\n",
        "\n",
        "for ex in test_examples:\n",
        "    prompt = format_nli_prompt(ex[\"premise\"], ex[\"hypothesis\"])\n",
        "    print(f\"Prompt: {prompt[:100]}...\")\n",
        "    print(f\"Expected: {ex['expected_label']}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d6809e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generalization test with the teacher model\n",
        "tokenizer = teacher.tokenizer\n",
        "\n",
        "for i, ex in enumerate(test_examples):\n",
        "    prompt = format_nli_prompt(ex[\"premise\"], ex[\"hypothesis\"])\n",
        "    \n",
        "    # Input tokenization\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=True\n",
        "    ).to(device)\n",
        "    \n",
        "    # Answer generation\n",
        "    outputs = teacher.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=128\n",
        "    )\n",
        "    \n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    print(f\"\\n=== Example {i+1} ===\")\n",
        "    print(f\"Premise: {ex['premise']}\")\n",
        "    print(f\"Hypothesis: {ex['hypothesis']}\")\n",
        "    print(f\"Expected: {ex['expected_label']}\")\n",
        "    print(f\"Teacher response: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b98632",
      "metadata": {},
      "source": [
        "## 3. Soft Logits of the Teacher\n",
        "\n",
        "Verify the generation of soft logits (probability distributions) that the student will have to imitate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc94b85a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test soft logits\n",
        "ex = test_examples[0]\n",
        "prompt = format_nli_prompt(ex[\"premise\"], ex[\"hypothesis\"])\n",
        "target = \"entailment. The man playing guitar is performing music.\"\n",
        "\n",
        "# Tokenizza input e target\n",
        "inputs = tokenizer(\n",
        "    prompt,\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=512,\n",
        "    truncation=True,\n",
        "    padding=True\n",
        ").to(device)\n",
        "\n",
        "targets = tokenizer(\n",
        "    target,\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding=True\n",
        ").to(device)\n",
        "\n",
        "# Prepare decoder_input_ids (shift right for teacher forcing)\n",
        "decoder_input_ids = targets[\"input_ids\"].clone()\n",
        "decoder_input_ids[:, 1:] = targets[\"input_ids\"][:, :-1].clone()\n",
        "decoder_input_ids[:, 0] = tokenizer.pad_token_id\n",
        "\n",
        "print(f\"Input shape: {inputs['input_ids'].shape}\")\n",
        "print(f\"Decoder input shape: {decoder_input_ids.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396ca0dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain soft logits from the teacher\n",
        "with torch.no_grad():\n",
        "    teacher_outputs = teacher(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        decoder_input_ids=decoder_input_ids\n",
        "    )\n",
        "\n",
        "teacher_logits = teacher_outputs[\"logits\"]\n",
        "print(f\"Teacher logits shape: {teacher_logits.shape}\")\n",
        "print(f\"Vocabulary size: {teacher_logits.size(-1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4907676f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert logits into soft probabilities\n",
        "temperature = 2.0  # Temperature for soft labels\n",
        "soft_probs = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "\n",
        "print(f\"Soft probabilities shape: {soft_probs.shape}\")\n",
        "print(f\"\\nFor the first token:\")\n",
        "print(f\"  Max probability: {soft_probs[0, 0].max().item():.4f}\")\n",
        "print(f\"  Min probability: {soft_probs[0, 0].min().item():.6f}\")\n",
        "print(f\"  Top-5 token indices: {soft_probs[0, 0].topk(5).indices.tolist()}\")\n",
        "\n",
        "# Decode top-5 tokens\n",
        "top5_tokens = soft_probs[0, 0].topk(5)\n",
        "print(f\"\\nTop-5 tokens with probabilities:\")\n",
        "for idx, prob in zip(top5_tokens.indices, top5_tokens.values):\n",
        "    token = tokenizer.decode([idx.item()])\n",
        "    print(f\"  '{token}': {prob.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e3bc47",
      "metadata": {},
      "source": [
        "## 4. Compare Teacher vs Student\n",
        "\n",
        "Let's compare the probability distributions between the teacher and the student."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f1698c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.models.student import StudentModel, StudentConfig\n",
        "\n",
        "# Load student model\n",
        "student_config = StudentConfig(\n",
        "    model_name=\"google/flan-t5-base\", # Smaller student model for faster training and inference\n",
        "    device=device\n",
        ")\n",
        "\n",
        "student = StudentModel(student_config)\n",
        "print(f\"\\nStudent model loaded!\")\n",
        "print(f\"Parameters student: {student.count_parameters():,}\")\n",
        "print(f\"Parameters teacher: {teacher.count_parameters():,}\")\n",
        "print(f\"Ratio: {teacher.count_parameters() / student.count_parameters():.1f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518ebeaf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain logits from the student\n",
        "student.model.eval()\n",
        "with torch.no_grad():\n",
        "    student_outputs = student(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        labels=targets[\"input_ids\"]\n",
        "    )\n",
        "\n",
        "student_logits = student_outputs[\"logits\"]\n",
        "print(f\"Student logits shape: {student_logits.shape}\")\n",
        "print(f\"Teacher logits shape: {teacher_logits.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6f06ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute KL divergence between student and teacher\n",
        "T = 2.0  # Temperature\n",
        "\n",
        "# Soft probabilities\n",
        "student_soft = F.log_softmax(student_logits / T, dim=-1)\n",
        "teacher_soft = F.softmax(teacher_logits / T, dim=-1)\n",
        "\n",
        "# Align vocabulary size if necessary\n",
        "if student_soft.size(-1) != teacher_soft.size(-1):\n",
        "    min_vocab = min(student_soft.size(-1), teacher_soft.size(-1))\n",
        "    student_soft = student_soft[:, :, :min_vocab]\n",
        "    teacher_soft = teacher_soft[:, :, :min_vocab]\n",
        "\n",
        "# KL divergence\n",
        "kl_div = F.kl_div(student_soft, teacher_soft, reduction='batchmean')\n",
        "print(f\"KL Divergence (student || teacher): {kl_div.item():.4f}\")\n",
        "\n",
        "# With temperature scaling\n",
        "kl_div_scaled = kl_div * (T ** 2)\n",
        "print(f\"KL Divergence scaled (T²): {kl_div_scaled.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e6b10a3",
      "metadata": {},
      "source": [
        "## 5. Visualize Distributions\n",
        "\n",
        "Let's visualize the probability distributions of the teacher and student."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9504876d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Take a specific token position to compare probabilities (here the first token) between teacher and student\n",
        "token_idx = 0\n",
        "top_k = 20\n",
        "\n",
        "teacher_probs = F.softmax(teacher_logits[0, token_idx], dim=-1)\n",
        "student_probs = F.softmax(student_logits[0, token_idx], dim=-1)\n",
        "\n",
        "# Top-k tokens from the teacher\n",
        "top_teacher = teacher_probs.topk(top_k)\n",
        "top_indices = top_teacher.indices.cpu().numpy()\n",
        "\n",
        "# Get the same probabilities from the student\n",
        "teacher_top_probs = top_teacher.values.cpu().numpy()\n",
        "student_top_probs = student_probs[top_indices].cpu().numpy()\n",
        "\n",
        "# Token names\n",
        "token_names = [tokenizer.decode([idx]) for idx in top_indices]\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x = np.arange(len(token_names))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, teacher_top_probs, width, label='Teacher (flan-t5-xl)', color='steelblue')\n",
        "bars2 = ax.bar(x + width/2, student_top_probs, width, label='Student (flan-t5-base)', color='coral')\n",
        "\n",
        "ax.set_xlabel('Token')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_title(f'Distribuzione probabilità - Token position {token_idx}')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(token_names, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b822e7",
      "metadata": {},
      "source": [
        "## 6. Memory Usage\n",
        "\n",
        "Evaluate memory usage for training with distillation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf60d88",
      "metadata": {},
      "outputs": [],
      "source": [
        "if device == \"cuda\":\n",
        "    print(\"=== GPU Memory Usage ===\")\n",
        "    print(f\"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "    print(f\"Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
        "    print(f\"Max Allocated: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(f\"Running on {device} - GPU memory stats not available\")\n",
        "    \n",
        "# Estimate memory usage based on parameter count and precision\n",
        "teacher_mem_gb = teacher.count_parameters() * 2 / 1e9  # FP16\n",
        "student_mem_gb = student.count_parameters() * 4 / 1e9  # FP32\n",
        "\n",
        "print(f\"\\n=== Model Memory Estimates ===\")\n",
        "print(f\"Teacher ({teacher_config.model_name}): ~{teacher_mem_gb:.1f} GB (FP16)\")\n",
        "print(f\"Student ({student_config.model_name}): ~{student_mem_gb:.1f} GB (FP32)\")\n",
        "print(f\"Total Estimated: ~{teacher_mem_gb + student_mem_gb:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64765329",
      "metadata": {},
      "source": [
        "## 7. Riepilogo\n",
        "\n",
        "Il teacher model è pronto per la knowledge distillation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75612a93",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"SUMMARY - TEACHER MODEL TESTING\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTeacher Model: {teacher_config.model_name}\")\n",
        "print(f\"  - Parameters: {teacher.count_parameters():,}\")\n",
        "print(f\"  - Device: {device}\")\n",
        "print(f\"  - FP16: {teacher_config.use_fp16}\")\n",
        "print(f\"\\nStudent Model: {student_config.model_name}\")\n",
        "print(f\"  - Parameters: {student.count_parameters():,}\")\n",
        "print(f\"  - Compression ratio: {teacher.count_parameters() / student.count_parameters():.1f}x\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
