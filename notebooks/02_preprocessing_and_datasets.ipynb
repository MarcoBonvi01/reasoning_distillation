{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Dataset Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# Configure the Python path to import project modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import required libraries for data processing and visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import custom modules for data loading, preprocessing, and dataset creation\n",
    "from src.data.data_loader import TeacherDataLoader, DatasetConfig\n",
    "from src.data.preprocessor import (\n",
    "    ReasoningPreprocessor,\n",
    "    PreprocessConfig,\n",
    "    TaskFormatter\n",
    ")\n",
    "from src.data.dataset import (\n",
    "    ESNLIDataset,\n",
    "    create_dataloaders\n",
    ")\n",
    "\n",
    "# Configure visualization styling\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Enable autoreload for automatic module reloading during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test TaskFormatter\n",
    "Verify that prompts are correctly formatted for both NLI and instruction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NLI TASK FORMATTING\n",
      "======================================================================\n",
      "\n",
      "Source (Input):\n",
      "nli premise: A person on a horse jumps over a broken down airplane. hypothesis: A person is training his horse for a competition.\n",
      "\n",
      "Target (Output):\n",
      "neutral explanation: The person is not necessarily training his horse.\n",
      "\n",
      "Source length: 23 words\n",
      "Target length: 10 words\n"
     ]
    }
   ],
   "source": [
    "# Initialize the task formatter\n",
    "formatter = TaskFormatter()\n",
    "\n",
    "# Test NLI (Natural Language Inference) formatting\n",
    "# This tests how the formatter creates prompts for NLI tasks\n",
    "print(\"=\" * 70)\n",
    "print(\"NLI TASK FORMATTING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define a sample NLI example with premise, hypothesis, label, and explanation\n",
    "premise = \"A person on a horse jumps over a broken down airplane.\"\n",
    "hypothesis = \"A person is training his horse for a competition.\"\n",
    "label = 1  # neutral (0=entailment, 1=neutral, 2=contradiction)\n",
    "explanation = \"The person is not necessarily training his horse.\"\n",
    "\n",
    "# Format the NLI sample into source (input) and target (output) texts\n",
    "source, target = formatter.format_nli(premise, hypothesis, label, explanation)\n",
    "\n",
    "# Display the formatted prompts and their statistics\n",
    "print(f\"\\nSource (Input):\\n{source}\")\n",
    "print(f\"\\nTarget (Output):\\n{target}\")\n",
    "print(f\"\\nSource length: {len(source.split())} words\")\n",
    "if target:\n",
    "    print(f\"Target length: {len(target.split())} words\")\n",
    "else:\n",
    "    print(\"Target length: 0 words (None)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test ReasoningPreprocessor\n",
    "Test tokenization and encoding for FLAN-T5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.preprocessor:Loading tokenizer: google/flan-t5-base\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/flan-t5-base/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/flan-t5-base/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e343f52207443438cc4079e51a0c594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/google/flan-t5-base/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/flan-t5-base/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/flan-t5-base/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/tokenizer_config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b44293e4c8463fa59472437edea7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/google/flan-t5-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/google/flan-t5-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/google/flan-t5-base/resolve/main/spiece.model \"HTTP/1.1 302 Found\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/google/flan-t5-base/xet-read-token/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9e547db683402baa4d0a4dbb511244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/google/flan-t5-base/resolve/main/tokenizer.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/flan-t5-base/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/tokenizer.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/flan-t5-base/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/tokenizer.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf8f9ac97184465b096479fa67f2cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/google/flan-t5-base/resolve/main/added_tokens.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/google/flan-t5-base/resolve/main/special_tokens_map.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/flan-t5-base/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/special_tokens_map.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/flan-t5-base/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/special_tokens_map.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ad9b1459034d338549b346c44acb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/google/flan-t5-base/resolve/main/chat_template.jinja \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TOKENIZER INFORMATION\n",
      "======================================================================\n",
      "{'model_name': 'google/flan-t5-base', 'vocab_size': 32100, 'max_source_length': 256, 'max_target_length': 128, 'pad_token': '<pad>', 'pad_token_id': 0, 'eos_token': '</s>', 'eos_token_id': 1}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the reasoning preprocessor with configuration\n",
    "# This handles tokenization and encoding for FLAN-T5 model\n",
    "config = PreprocessConfig(\n",
    "    model_name=\"google/flan-t5-base\",  # Use FLAN-T5 base model tokenizer\n",
    "    max_source_length=256,              # Maximum input sequence length\n",
    "    max_target_length=128,              # Maximum output sequence length\n",
    "    padding=\"max_length\"                # Pad sequences to max length\n",
    ")\n",
    "\n",
    "preprocessor = ReasoningPreprocessor(config)\n",
    "\n",
    "# Display information about the loaded tokenizer\n",
    "print(\"=\" * 70)\n",
    "print(\"TOKENIZER INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(preprocessor.get_tokenizer_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TOKENIZING e-SNLI SAMPLE\n",
      "======================================================================\n",
      "\n",
      "Original Sample:\n",
      "Premise: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is training his horse for a competition.\n",
      "Label: 1 (neutral)\n",
      "Explanation: The person is not necessarily training his horse.\n",
      "\n",
      "======================================================================\n",
      "STEP 1: TOKENIZE THE SAMPLE\n",
      "======================================================================\n",
      "\n",
      "Tokenized Tensor Shapes:\n",
      "Input IDs:       torch.Size([256])       → 256 tokens for input\n",
      "Attention Mask:  torch.Size([256])  → 256 mask values\n",
      "Labels:          torch.Size([128])          → 128 tokens for output\n",
      "\n",
      "======================================================================\n",
      "STEP 2: EXAMINE INPUT TOKENS (MODEL INPUT)\n",
      "======================================================================\n",
      "\n",
      "First 20 Input Token IDs:\n",
      "[3, 29, 40, 23, 3, 17398, 10, 71, 568, 30, 3, 9, 4952, 4418, 7, 147, 3, 9, 4335, 323]\n",
      "\n",
      "What these IDs mean (decoded one by one):\n",
      "  Token 0: ID=    3 → ''\n",
      "  Token 1: ID=   29 → 'n'\n",
      "  Token 2: ID=   40 → 'l'\n",
      "  Token 3: ID=   23 → 'i'\n",
      "  Token 4: ID=    3 → ''\n",
      "  Token 5: ID=17398 → 'premise'\n",
      "  Token 6: ID=   10 → ':'\n",
      "  Token 7: ID=   71 → 'A'\n",
      "  Token 8: ID=  568 → 'person'\n",
      "  Token 9: ID=   30 → 'on'\n",
      "\n",
      "Full Decoded Input:\n",
      "nli premise: A person on a horse jumps over a broken down airplane. hypothesis: A person is training his horse for a competition.\n",
      "\n",
      "This is what the model sees as input!\n",
      "\n",
      "======================================================================\n",
      "STEP 3: EXAMINE ATTENTION MASK\n",
      "======================================================================\n",
      "\n",
      "First 30 Attention Mask Values:\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Attention Statistics:\n",
      "  Real tokens (1):  36\n",
      "  Padding (0):      220\n",
      "  Total:            256\n",
      "\n",
      "The model only processes the first 36 tokens, ignoring the rest!\n",
      "\n",
      "======================================================================\n",
      "STEP 4: EXAMINE LABEL TOKENS (MODEL OUTPUT/TARGET)\n",
      "======================================================================\n",
      "\n",
      "First 20 Label Token IDs:\n",
      "[7163, 7295, 10, 37, 568, 19, 59, 6539, 761, 112, 4952, 5, 1, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "Label Statistics:\n",
      "  Real label tokens:  13\n",
      "  Padding (-100):     115\n",
      "  Total:              128\n",
      "\n",
      "What these label IDs mean (first 10 non-padding):\n",
      "  Token 0: ID= 7163 → 'neutral'\n",
      "  Token 1: ID= 7295 → 'explanation'\n",
      "  Token 2: ID=   10 → ':'\n",
      "  Token 3: ID=   37 → 'The'\n",
      "  Token 4: ID=  568 → 'person'\n",
      "  Token 5: ID=   19 → 'is'\n",
      "  Token 6: ID=   59 → 'not'\n",
      "  Token 7: ID= 6539 → 'necessarily'\n",
      "  Token 8: ID=  761 → 'training'\n",
      "  Token 9: ID=  112 → 'his'\n",
      "\n",
      "Full Decoded Labels (What model should predict):\n",
      "neutral explanation: The person is not necessarily training his horse.\n",
      "\n",
      "This is what we want the model to generate!\n",
      "\n",
      "======================================================================\n",
      "TOKENIZATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "The preprocessor has:\n",
      "  1. Formatted the NLI task into a text prompt\n",
      "  2. Converted input text → 36 numerical tokens\n",
      "  3. Converted output text → 13 numerical tokens\n",
      "  4. Added padding to reach max lengths (256/128)\n",
      "  5. Created attention masks to ignore padding\n",
      "\n",
      "Training objective:\n",
      "  Given INPUT:  nli premise: A person on a horse jumps over a broken down airplane. hypothesis: A person is training...\n",
      "  Predict:      neutral explanation: The person is not necessarily training his horse.\n"
     ]
    }
   ],
   "source": [
    "# Test tokenization on an e-SNLI sample\n",
    "# This verifies that the preprocessor correctly tokenizes NLI examples\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOKENIZING e-SNLI SAMPLE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "esnli_sample = {\n",
    "    'premise': \"A person on a horse jumps over a broken down airplane.\",\n",
    "    'hypothesis': \"A person is training his horse for a competition.\",\n",
    "    'label': 1,  # neutral\n",
    "    'explanation_1': \"The person is not necessarily training his horse.\"\n",
    "}\n",
    "\n",
    "print(\"\\nOriginal Sample:\")\n",
    "print(f\"Premise: {esnli_sample['premise']}\")\n",
    "print(f\"Hypothesis: {esnli_sample['hypothesis']}\")\n",
    "print(f\"Label: {esnli_sample['label']} (neutral)\")\n",
    "print(f\"Explanation: {esnli_sample['explanation_1']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TOKENIZATION PROCESS\n",
    "# ============================================================================\n",
    "# The preprocessor will:\n",
    "# 1. Format the sample into a prompt (using TaskFormatter)\n",
    "# 2. Tokenize both input (source) and output (target) using T5 tokenizer\n",
    "# 3. Convert text into numerical IDs that the model can process\n",
    "# 4. Create attention masks (which tokens to pay attention to)\n",
    "# 5. Create labels for training (what the model should predict)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 1: TOKENIZE THE SAMPLE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "tokenized = preprocessor.preprocess_esnli_sample(esnli_sample)\n",
    "\n",
    "# ============================================================================\n",
    "# UNDERSTANDING THE OUTPUT TENSORS\n",
    "# ============================================================================\n",
    "# input_ids: The numerical representation of the input text\n",
    "#            Each number corresponds to a token in the vocabulary\n",
    "# attention_mask: Binary mask (1=real token, 0=padding)\n",
    "#                 Tells the model which tokens to attend to\n",
    "# labels: The numerical representation of the target/output text\n",
    "#         Uses -100 for padding\n",
    "\n",
    "print(\"\\nTokenized Tensor Shapes:\")\n",
    "print(f\"Input IDs:       {tokenized['input_ids'].shape}       → {tokenized['input_ids'].shape[0]} tokens for input\")\n",
    "print(f\"Attention Mask:  {tokenized['attention_mask'].shape}  → {tokenized['attention_mask'].shape[0]} mask values\")\n",
    "print(f\"Labels:          {tokenized['labels'].shape}          → {tokenized['labels'].shape[0]} tokens for output\")\n",
    "\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: EXAMINE INPUT TOKENS (MODEL INPUT)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show the first 20 token IDs\n",
    "# These are numerical representations of the input prompt\n",
    "input_token_ids = tokenized['input_ids'][:20].tolist()\n",
    "print(f\"\\nFirst 20 Input Token IDs:\")\n",
    "print(input_token_ids)\n",
    "\n",
    "# Decode these IDs back to see what they represent\n",
    "print(f\"\\nWhat these IDs mean (decoded one by one):\")\n",
    "for i, token_id in enumerate(input_token_ids[:10]):  # Show first 10 for clarity\n",
    "    token_text = preprocessor.tokenizer.decode([token_id])\n",
    "    print(f\"  Token {i}: ID={token_id:5d} → '{token_text}'\")\n",
    "\n",
    "# Decode the full input to see the complete formatted prompt\n",
    "print(f\"\\nFull Decoded Input:\")\n",
    "decoded_input = preprocessor.decode_prediction(tokenized['input_ids'])\n",
    "print(decoded_input)\n",
    "print(f\"\\nThis is what the model sees as input!\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMINING ATTENTION MASK\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3: EXAMINE ATTENTION MASK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "attention_values = tokenized['attention_mask'][:30].tolist()\n",
    "print(f\"\\nFirst 30 Attention Mask Values:\")\n",
    "print(attention_values)\n",
    "\n",
    "# Count real tokens vs padding\n",
    "num_real_tokens = tokenized['attention_mask'].sum().item()\n",
    "num_padding = len(tokenized['attention_mask']) - num_real_tokens\n",
    "print(f\"\\nAttention Statistics:\")\n",
    "print(f\"  Real tokens (1):  {num_real_tokens}\")\n",
    "print(f\"  Padding (0):      {num_padding}\")\n",
    "print(f\"  Total:            {len(tokenized['attention_mask'])}\")\n",
    "print(f\"\\nThe model only processes the first {num_real_tokens} tokens, ignoring the rest!\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMINING LABEL TOKENS (What the model should OUTPUT)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: EXAMINE LABEL TOKENS (MODEL OUTPUT/TARGET)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show the first 20 label token IDs\n",
    "# -100 is a special value\n",
    "label_token_ids = tokenized['labels'][:20].tolist()\n",
    "print(f\"\\nFirst 20 Label Token IDs:\")\n",
    "print(label_token_ids)\n",
    "\n",
    "# Count real labels vs padding (-100)\n",
    "num_real_labels = (tokenized['labels'] != -100).sum().item()\n",
    "num_padding_labels = (tokenized['labels'] == -100).sum().item()\n",
    "print(f\"\\nLabel Statistics:\")\n",
    "print(f\"  Real label tokens:  {num_real_labels}\")\n",
    "print(f\"  Padding (-100):     {num_padding_labels}\")\n",
    "print(f\"  Total:              {len(tokenized['labels'])}\")\n",
    "\n",
    "# Decode labels to see what the model should predict\n",
    "# We need to replace -100 with the actual pad token ID for decoding\n",
    "print(f\"\\nWhat these label IDs mean (first 10 non-padding):\")\n",
    "non_padding_labels = tokenized['labels'][tokenized['labels'] != -100][:10]\n",
    "for i, token_id in enumerate(non_padding_labels.tolist()):\n",
    "    token_text = preprocessor.tokenizer.decode([token_id])\n",
    "    print(f\"  Token {i}: ID={token_id:5d} → '{token_text}'\")\n",
    "\n",
    "print(f\"\\nFull Decoded Labels (What model should predict):\")\n",
    "labels_for_decode = tokenized['labels'].clone()\n",
    "labels_for_decode[labels_for_decode == -100] = preprocessor.tokenizer.pad_token_id\n",
    "decoded_labels = preprocessor.decode_prediction(labels_for_decode)\n",
    "print(decoded_labels)\n",
    "print(f\"\\nThis is what we want the model to generate!\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOKENIZATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThe preprocessor has:\")\n",
    "print(f\"  1. Formatted the NLI task into a text prompt\")\n",
    "print(f\"  2. Converted input text → {num_real_tokens} numerical tokens\")\n",
    "print(f\"  3. Converted output text → {num_real_labels} numerical tokens\")\n",
    "print(f\"  4. Added padding to reach max lengths ({config.max_source_length}/{config.max_target_length})\")\n",
    "print(f\"  5. Created attention masks to ignore padding\")\n",
    "print(f\"\\nTraining objective:\")\n",
    "print(f\"  Given INPUT:  {decoded_input[:100]}...\")\n",
    "print(f\"  Predict:      {decoded_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ATTENTION MASK VISUALIZATION\n",
      "======================================================================\n",
      "\n",
      "Actual content tokens: 36 / 256\n",
      "Padding tokens: 220\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the attention mask\n",
    "# This shows which tokens the model should attend to (1) and which to ignore (0)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ATTENTION MASK VISUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Convert tensors to numpy for visualization\n",
    "attention_mask = tokenized['attention_mask'].numpy()\n",
    "input_ids = tokenized['input_ids'].numpy()\n",
    "\n",
    "# Calculate how many tokens are actual content vs padding\n",
    "content_length = attention_mask.sum()\n",
    "print(f\"\\nActual content tokens: {content_length} / {len(attention_mask)}\")\n",
    "print(f\"Padding tokens: {len(attention_mask) - content_length}\")\n",
    "\n",
    "# Create a heatmap visualization of the attention mask\n",
    "plt.figure(figsize=(14, 3))\n",
    "plt.imshow(attention_mask.reshape(1, -1), cmap='RdYlGn', aspect='auto')\n",
    "plt.colorbar(label='Attention (1=attend, 0=ignore)')\n",
    "plt.xlabel('Token Position')\n",
    "plt.yticks([])\n",
    "plt.title('Attention Mask Pattern')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Real Data and Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.data_loader:Loading e-SNLI dataset from GitHub (OanaMariaCamburu/e-SNLI)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/csv/csv.py \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c9745f76a14309bdd0274f9af97039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/90.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a78c7d138b4388828b2a7292a11e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/csv/csv.py \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc486e158ff74b2a861322d9f54e5794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/99.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98da62c6ac9b402da76c43e4541fefef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26716e20edbe499c9482da2d3c75be90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/259999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load small subsets of e-SNLI data for testing\n",
    "# Using small subsets makes testing faster during development\n",
    "print(\"Loading data...\")\n",
    "loader = TeacherDataLoader()\n",
    "\n",
    "# Load the full e-SNLI dataset from HuggingFace\n",
    "esnli_full = loader.load_esnli()\n",
    "\n",
    "# Select small subsets for quick testing\n",
    "esnli_train_small = esnli_full['train'].select(range(100))  # First 100 training samples\n",
    "esnli_val_small = esnli_full['validation'].select(range(50))  # First 50 validation samples\n",
    "\n",
    "print(f\"Loaded {len(esnli_train_small)} e-SNLI train samples\")\n",
    "print(f\"Loaded {len(esnli_val_small)} e-SNLI val samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets from the loaded data\n",
    "# These datasets handle tokenization and caching for efficient data loading\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CREATING PYTORCH DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize preprocessor with configuration\n",
    "preprocess_config = PreprocessConfig(\n",
    "    model_name=\"google/flan-t5-base\",\n",
    "    max_source_length=256,\n",
    "    max_target_length=128\n",
    ")\n",
    "preprocessor = ReasoningPreprocessor(preprocess_config)\n",
    "\n",
    "# Create training dataset with caching enabled\n",
    "esnli_train_dataset = ESNLIDataset(\n",
    "    esnli_train_small,\n",
    "    preprocessor,\n",
    "    cache_dir=\"../data/cache/esnli_train\",  # Cache directory for faster reloading\n",
    "    use_cache=True                           # Enable caching\n",
    ")\n",
    "\n",
    "# Create validation dataset with caching enabled\n",
    "esnli_val_dataset = ESNLIDataset(\n",
    "    esnli_val_small,\n",
    "    preprocessor,\n",
    "    cache_dir=\"../data/cache/esnli_val\",\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "print(f\"\\ne-SNLI train dataset: {len(esnli_train_dataset)} samples\")\n",
    "print(f\"e-SNLI val dataset: {len(esnli_val_dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset indexing\n",
    "# Verify that we can access individual samples from the dataset\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TESTING DATASET INDEXING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the first sample from the training dataset\n",
    "sample_idx = 0\n",
    "esnli_sample = esnli_train_dataset[sample_idx]\n",
    "\n",
    "# Display the structure of a dataset sample\n",
    "print(f\"\\nSample keys: {esnli_sample.keys()}\")\n",
    "print(f\"\\nShapes:\")\n",
    "for key, value in esnli_sample.items():\n",
    "    print(f\"  {key}: {value.shape}\")\n",
    "\n",
    "# Decode the tokenized sample to verify it's correct\n",
    "print(f\"\\n--- Decoded Sample ---\")\n",
    "decoded_input = preprocessor.decode_prediction(esnli_sample['input_ids'])\n",
    "print(f\"Input: {decoded_input}\")\n",
    "\n",
    "# Decode labels (replace -100 padding with pad token)\n",
    "labels_for_decode = esnli_sample['labels'].clone()\n",
    "labels_for_decode[labels_for_decode == -100] = preprocessor.tokenizer.pad_token_id\n",
    "decoded_target = preprocessor.decode_prediction(labels_for_decode)\n",
    "print(f\"Target: {decoded_target}\")\n",
    "\n",
    "# Show the original raw data before preprocessing\n",
    "raw = esnli_train_dataset.get_raw_sample(sample_idx)\n",
    "print(f\"\\n--- Raw Sample ---\")\n",
    "print(f\"Premise: {raw['premise']}\")\n",
    "print(f\"Hypothesis: {raw['hypothesis']}\")\n",
    "print(f\"Label: {raw['label']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test DataLoader Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for batch training\n",
    "# DataLoaders handle batching, shuffling, and parallel data loading\n",
    "print(\"=\" * 70)\n",
    "print(\"CREATING DATALOADERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "batch_size = 8  # Number of samples per batch\n",
    "\n",
    "# Create train and validation dataloaders\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_dataset=esnli_train_dataset,\n",
    "    val_dataset=esnli_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,  # Use 0 for notebook compatibility (no multiprocessing)\n",
    "    pad_token_id=preprocessor.tokenizer.pad_token_id,\n",
    "    shuffle_train=True  # Shuffle training data for better learning\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain DataLoader: {len(train_loader)} batches\")\n",
    "print(f\"Val DataLoader: {len(val_loader)} batches\")\n",
    "print(f\"\\nBatch size: {batch_size}\")\n",
    "print(f\"Total train samples: {len(train_loader) * batch_size}\")\n",
    "print(f\"Total val samples: {len(val_loader) * batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch iteration\n",
    "# Verify that batches are correctly formed and have the expected structure\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TESTING BATCH ITERATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the first batch from the training dataloader\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Display batch structure\n",
    "print(f\"\\nBatch keys: {batch.keys()}\")\n",
    "print(f\"\\nBatch shapes:\")\n",
    "for key, value in batch.items():\n",
    "    print(f\"  {key}: {value.shape}\")\n",
    "\n",
    "# Verify batch dimensions are correct\n",
    "assert batch['input_ids'].shape[0] == batch_size, \"Batch size mismatch!\"\n",
    "assert batch['input_ids'].shape[1] == config.max_source_length, \"Sequence length mismatch!\"\n",
    "print(f\"\\nBatch dimensions correct!\")\n",
    "\n",
    "# Check tensor properties\n",
    "print(f\"\\nTensor device: {batch['input_ids'].device}\")\n",
    "print(f\"Tensor dtype: {batch['input_ids'].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display decoded samples from the batch\n",
    "# This helps verify that batching hasn't corrupted the data\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BATCH SAMPLES PREVIEW\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "n_display = 3  # Number of samples to display\n",
    "\n",
    "# Loop through first few samples in the batch\n",
    "for i in range(min(n_display, batch_size)):\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    \n",
    "    # Decode input sequence\n",
    "    input_text = preprocessor.decode_prediction(batch['input_ids'][i])\n",
    "    print(f\"Input: {input_text}\")\n",
    "    \n",
    "    # Decode target sequence (replace -100 padding)\n",
    "    labels = batch['labels'][i].clone()\n",
    "    labels[labels == -100] = preprocessor.tokenizer.pad_token_id\n",
    "    target_text = preprocessor.decode_prediction(labels)\n",
    "    print(f\"Target: {target_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure preprocessing speed and caching effectiveness\n",
    "# This helps evaluate the performance benefits of caching\n",
    "import time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PREPROCESSING PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test with caching enabled\n",
    "n_iterations = 3  # Run multiple iterations to see cache speedup\n",
    "\n",
    "print(\"\\n--- With Caching ---\")\n",
    "times_cached = []\n",
    "\n",
    "# Run multiple iterations to measure cache performance\n",
    "for iteration in range(n_iterations):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Access 50 samples from the dataset\n",
    "    for i in range(50):\n",
    "        _ = esnli_train_dataset[i]\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    times_cached.append(elapsed)\n",
    "    print(f\"Iteration {iteration+1}: {elapsed:.3f}s ({50/elapsed:.1f} samples/sec)\")\n",
    "\n",
    "# Calculate average performance and speedup from caching\n",
    "print(f\"\\nAverage: {np.mean(times_cached):.3f}s\")\n",
    "print(f\"Speedup (iter 2 vs iter 1): {times_cached[0]/times_cached[1]:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze token length distribution\n",
    "# This helps understand if our max_length settings are appropriate\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOKEN LENGTH DISTRIBUTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "input_lengths = []\n",
    "label_lengths = []\n",
    "\n",
    "# Iterate through dataset and collect token lengths\n",
    "for i in tqdm(range(len(esnli_train_dataset)), desc=\"Analyzing lengths\"):\n",
    "    sample = esnli_train_dataset[i]\n",
    "    \n",
    "    # Count non-padding tokens for input and labels\n",
    "    input_len = sample['attention_mask'].sum().item()\n",
    "    label_len = (sample['labels'] != -100).sum().item()\n",
    "    \n",
    "    input_lengths.append(input_len)\n",
    "    label_lengths.append(label_len)\n",
    "\n",
    "# Create histograms to visualize token length distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot input length distribution\n",
    "axes[0].hist(input_lengths, bins=30, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(np.mean(input_lengths), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(input_lengths):.1f}')\n",
    "axes[0].set_xlabel('Input Length (tokens)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Input Token Length Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot target length distribution\n",
    "axes[1].hist(label_lengths, bins=30, color='#e74c3c', alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(np.mean(label_lengths), color='red', linestyle='--',\n",
    "                label=f'Mean: {np.mean(label_lengths):.1f}')\n",
    "axes[1].set_xlabel('Target Length (tokens)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Target Token Length Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics about token lengths\n",
    "print(f\"\\nInput lengths - Mean: {np.mean(input_lengths):.1f}, Std: {np.std(input_lengths):.1f}\")\n",
    "print(f\"Target lengths - Mean: {np.mean(label_lengths):.1f}, Std: {np.std(label_lengths):.1f}\")\n",
    "print(f\"\\nMax configured lengths: Input={config.max_source_length}, Target={config.max_target_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test label and explanation extraction from predictions\n",
    "# These functions parse model outputs to extract labels and explanations\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING PREDICTION PARSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create test predictions in different formats\n",
    "test_predictions = [\n",
    "    \"entailment explanation: The person is definitely on a horse.\",\n",
    "    \"neutral explanation: We cannot determine if they are training.\",\n",
    "    \"contradiction\",\n",
    "    \"entailment This clearly follows from the premise.\"\n",
    "]\n",
    "\n",
    "# Test extraction functions on each prediction\n",
    "for pred in test_predictions:\n",
    "    print(f\"\\nPrediction: {pred}\")\n",
    "    \n",
    "    # Extract the predicted label (entailment/neutral/contradiction)\n",
    "    label = preprocessor.extract_label_from_prediction(pred)\n",
    "    # Extract the explanation text\n",
    "    explanation = preprocessor.extract_explanation_from_prediction(pred)\n",
    "    \n",
    "    print(f\"  → Label: {label}\")\n",
    "    print(f\"  → Explanation: {explanation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive summary of all tests performed\n",
    "# This provides a final validation that all components are working correctly\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREPROCESSING PIPELINE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nTaskFormatter\")\n",
    "print(\"  • NLI tasks formatted correctly\")\n",
    "print(\"  • Instruction tasks formatted correctly\")\n",
    "\n",
    "print(\"\\nReasoningPreprocessor\")\n",
    "print(f\"  • Tokenizer loaded: {preprocessor.config.model_name}\")\n",
    "print(f\"  • Max source length: {preprocessor.config.max_source_length}\")\n",
    "print(f\"  • Max target length: {preprocessor.config.max_target_length}\")\n",
    "print(\"  • Tokenization working correctly\")\n",
    "print(\"  • Padding/truncation working\")\n",
    "\n",
    "print(\"\\nPyTorch Datasets\")\n",
    "print(f\"  • e-SNLI train: {len(esnli_train_dataset)} samples\")\n",
    "print(f\"  • e-SNLI val: {len(esnli_val_dataset)} samples\")\n",
    "print(\"  • Caching working correctly\")\n",
    "\n",
    "print(\"\\nDataLoaders\")\n",
    "print(f\"  • Train batches: {len(train_loader)}\")\n",
    "print(f\"  • Val batches: {len(val_loader)}\")\n",
    "print(f\"  • Batch size: {batch_size}\")\n",
    "print(\"  • Collation working correctly\")\n",
    "\n",
    "print(\"\\nPerformance\")\n",
    "print(f\"  • Average preprocessing time: {np.mean(times_cached[1:]):.3f}s per 50 samples\")\n",
    "print(f\"  • Caching speedup: ~{times_cached[0]/np.mean(times_cached[1:]):.1f}x\")\n",
    "print(f\"  • Average input tokens: {np.mean(input_lengths):.1f}\")\n",
    "print(f\"  • Average target tokens: {np.mean(label_lengths):.1f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
