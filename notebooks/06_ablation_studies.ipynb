{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e320ca5",
   "metadata": {},
   "source": [
    "# Ablation Studies Notebook\n",
    "## Reasoning Distillation Project\n",
    "\n",
    "This notebook performs systematic ablation studies to understand:\n",
    "1. Effect of label smoothing (0.0, 0.1, 0.2)\n",
    "2. Temperature variations in generation\n",
    "3. Impact of training data size (10%, 50%, 100%)\n",
    "4. Beam search vs sampling strategies\n",
    "5. Learning rate sensitivity\n",
    "6. Effect of max sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from src.data.data_loader import TeacherDataLoader\n",
    "from src.data.preprocessor import ReasoningPreprocessor, PreprocessConfig\n",
    "from src.data.dataset import ESNLIDataset, create_dataloaders\n",
    "\n",
    "from src.models.student import StudentModel, StudentConfig\n",
    "\n",
    "from src.training.distillation import (\n",
    "    DistillationConfig,\n",
    "    SequenceLevelDistillation\n",
    ")\n",
    "\n",
    "from src.training.trainer import Trainer, TrainingConfig\n",
    "\n",
    "from src.evaluation.evaluator import Evaluator, EvaluationConfig\n",
    "from src.evaluation.metrics import MetricsConfig, format_metrics\n",
    "\n",
    "# Styling\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc9323",
   "metadata": {},
   "source": [
    "## 1. Load Base Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8612c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "loader = TeacherDataLoader()\n",
    "esnli_data = loader.load_esnli()\n",
    "\n",
    "# Use subset for faster ablation experiments\n",
    "train_subset = esnli_data['train'].select(range(500))  # 500 samples\n",
    "val_subset = esnli_data['validation'].select(range(100))  # 100 samples\n",
    "\n",
    "print(f\"\\nâœ“ Train samples: {len(train_subset)}\")\n",
    "print(f\"âœ“ Val samples: {len(val_subset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35b85c",
   "metadata": {},
   "source": [
    "## 2. Ablation Study 1: Label Smoothing\n",
    "\n",
    "Test the effect of different label smoothing values on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea96130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation 1: Label Smoothing\n",
    "print(\"=\" * 70)\n",
    "print(\"ABLATION STUDY 1: LABEL SMOOTHING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "smoothing_values = [0.0, 0.1, 0.2]\n",
    "smoothing_results = []\n",
    "\n",
    "# Prepare data\n",
    "preprocess_config = PreprocessConfig(\n",
    "    model_name=\"google/flan-t5-small\",\n",
    "    max_source_length=128,\n",
    "    max_target_length=64\n",
    ")\n",
    "\n",
    "preprocessor = ReasoningPreprocessor(preprocess_config)\n",
    "train_dataset = ESNLIDataset(train_subset, preprocessor, use_cache=True)\n",
    "val_dataset = ESNLIDataset(val_subset, preprocessor, use_cache=True)\n",
    "\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    pad_token_id=preprocessor.tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "for smoothing in smoothing_values:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing Label Smoothing = {smoothing}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create fresh model\n",
    "    student_config = StudentConfig(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        max_source_length=128,\n",
    "        max_target_length=64,\n",
    "        device=device\n",
    "    )\n",
    "    student = StudentModel(student_config)\n",
    "    \n",
    "    # Create distillation strategy\n",
    "    distill_config = DistillationConfig(\n",
    "        ce_weight=1.0,\n",
    "        label_smoothing=smoothing\n",
    "    )\n",
    "    distillation_strategy = SequenceLevelDistillation(distill_config)\n",
    "    \n",
    "    # Train\n",
    "    training_config = TrainingConfig(\n",
    "        num_epochs=3,\n",
    "        learning_rate=5e-5,\n",
    "        eval_steps=20,\n",
    "        save_steps=1000,  # Don't save\n",
    "        logging_steps=10,\n",
    "        output_dir=f\"../experiments/ablation_smoothing_{smoothing}\",\n",
    "        eval_strategy=\"steps\"\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=student,\n",
    "        train_dataloader=train_loader,\n",
    "        eval_dataloader=val_loader,\n",
    "        distillation_strategy=distillation_strategy,\n",
    "        config=training_config\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = trainer.train()\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_config = EvaluationConfig(\n",
    "        metrics_config=MetricsConfig(\n",
    "            compute_rouge=True,\n",
    "            compute_bertscore=False,\n",
    "            compute_faithfulness=True\n",
    "        ),\n",
    "        save_predictions=False,\n",
    "        output_dir=f\"../experiments/ablation_smoothing_{smoothing}_eval\"\n",
    "    )\n",
    "    \n",
    "    evaluator = Evaluator(student, eval_config)\n",
    "    results = evaluator.evaluate(val_loader, split_name=\"val\")\n",
    "    \n",
    "    # Store results\n",
    "    smoothing_results.append({\n",
    "        'smoothing': smoothing,\n",
    "        'accuracy': results['metrics']['label_accuracy'],\n",
    "        'rouge1': results['metrics']['rouge1'],\n",
    "        'rougeL': results['metrics']['rougeL'],\n",
    "        'faithfulness': results['metrics']['faithfulness'],\n",
    "        'final_train_loss': history['train_history'][-1]['loss'],\n",
    "        'final_eval_loss': history['eval_history'][-1]['eval_loss'] if history['eval_history'] else None,\n",
    "        'training_time': training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nâœ“ Smoothing {smoothing} completed\")\n",
    "    print(f\"  Accuracy: {results['metrics']['label_accuracy']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {results['metrics']['rougeL']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LABEL SMOOTHING ABLATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label smoothing results\n",
    "smoothing_df = pd.DataFrame(smoothing_results)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "metrics_to_plot = ['accuracy', 'rouge1', 'rougeL', 'faithfulness']\n",
    "colors_palette = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']\n",
    "\n",
    "for idx, (metric, color) in enumerate(zip(metrics_to_plot, colors_palette)):\n",
    "    axes[idx].plot(smoothing_df['smoothing'], smoothing_df[metric], \n",
    "                   marker='o', linewidth=2, markersize=10, color=color)\n",
    "    axes[idx].set_xlabel('Label Smoothing')\n",
    "    axes[idx].set_ylabel(metric.upper())\n",
    "    axes[idx].set_title(f'{metric.upper()} vs Label Smoothing')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for x, y in zip(smoothing_df['smoothing'], smoothing_df[metric]):\n",
    "        axes[idx].text(x, y + 0.01, f'{y:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Ablation Study: Label Smoothing Impact', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLabel Smoothing Results Summary:\")\n",
    "print(smoothing_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c0a76",
   "metadata": {},
   "source": [
    "## 3. Ablation Study 2: Training Data Size\n",
    "\n",
    "Evaluate how model performance scales with training data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b97a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation 2: Training Data Size\n",
    "print(\"=\" * 70)\n",
    "print(\"ABLATION STUDY 2: TRAINING DATA SIZE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "data_fractions = [0.1, 0.5, 1.0]\n",
    "data_size_results = []\n",
    "\n",
    "# Use larger base dataset for this study\n",
    "full_train = esnli_data['train'].select(range(2000))\n",
    "\n",
    "for fraction in data_fractions:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing Data Fraction = {fraction*100}%\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Sample data\n",
    "    n_samples = int(len(full_train) * fraction)\n",
    "    train_fraction = full_train.select(range(n_samples))\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset_frac = ESNLIDataset(train_fraction, preprocessor, use_cache=True)\n",
    "    train_loader_frac, _ = create_dataloaders(\n",
    "        train_dataset=train_dataset_frac,\n",
    "        val_dataset=val_dataset,\n",
    "        batch_size=16,\n",
    "        num_workers=0,\n",
    "        pad_token_id=preprocessor.tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Create fresh model\n",
    "    student = StudentModel(StudentConfig(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        max_source_length=128,\n",
    "        max_target_length=64,\n",
    "        device=device\n",
    "    ))\n",
    "    \n",
    "    distillation_strategy = SequenceLevelDistillation(DistillationConfig(\n",
    "        ce_weight=1.0,\n",
    "        label_smoothing=0.1\n",
    "    ))\n",
    "    \n",
    "    # Train\n",
    "    training_config = TrainingConfig(\n",
    "        num_epochs=3,\n",
    "        learning_rate=5e-5,\n",
    "        eval_steps=20,\n",
    "        save_steps=1000,\n",
    "        logging_steps=10,\n",
    "        output_dir=f\"../experiments/ablation_datasize_{fraction}\",\n",
    "        eval_strategy=\"steps\"\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=student,\n",
    "        train_dataloader=train_loader_frac,\n",
    "        eval_dataloader=val_loader,\n",
    "        distillation_strategy=distillation_strategy,\n",
    "        config=training_config\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = trainer.train()\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    evaluator = Evaluator(student, EvaluationConfig(\n",
    "        metrics_config=MetricsConfig(\n",
    "            compute_rouge=True,\n",
    "            compute_bertscore=False,\n",
    "            compute_faithfulness=True\n",
    "        ),\n",
    "        save_predictions=False,\n",
    "        output_dir=f\"../experiments/ablation_datasize_{fraction}_eval\"\n",
    "    ))\n",
    "    \n",
    "    results = evaluator.evaluate(val_loader, split_name=\"val\")\n",
    "    \n",
    "    # Store results\n",
    "    data_size_results.append({\n",
    "        'fraction': fraction,\n",
    "        'n_samples': n_samples,\n",
    "        'accuracy': results['metrics']['label_accuracy'],\n",
    "        'rouge1': results['metrics']['rouge1'],\n",
    "        'rougeL': results['metrics']['rougeL'],\n",
    "        'faithfulness': results['metrics']['faithfulness'],\n",
    "        'training_time': training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nâœ“ Data fraction {fraction} completed\")\n",
    "    print(f\"  Samples: {n_samples}\")\n",
    "    print(f\"  Accuracy: {results['metrics']['label_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA SIZE ABLATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data size results\n",
    "datasize_df = pd.DataFrame(data_size_results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Performance vs Data Size\n",
    "metrics = ['accuracy', 'rouge1', 'rougeL', 'faithfulness']\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']\n",
    "\n",
    "for metric, color in zip(metrics, colors):\n",
    "    axes[0].plot(datasize_df['n_samples'], datasize_df[metric], \n",
    "                 marker='o', linewidth=2, markersize=8, label=metric.upper(), color=color)\n",
    "\n",
    "axes[0].set_xlabel('Number of Training Samples')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Performance vs Training Data Size')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Training Time vs Data Size\n",
    "axes[1].plot(datasize_df['n_samples'], datasize_df['training_time'], \n",
    "             marker='s', linewidth=2, markersize=8, color='#9b59b6')\n",
    "axes[1].set_xlabel('Number of Training Samples')\n",
    "axes[1].set_ylabel('Training Time (seconds)')\n",
    "axes[1].set_title('Training Time vs Data Size')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "for x, y in zip(datasize_df['n_samples'], datasize_df['training_time']):\n",
    "    axes[1].text(x, y + 5, f'{y:.0f}s', ha='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Ablation Study: Training Data Size Impact', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData Size Results Summary:\")\n",
    "print(datasize_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b300feff",
   "metadata": {},
   "source": [
    "## 4. Ablation Study 3: Generation Temperature\n",
    "\n",
    "Test different temperature values during generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation 3: Generation Temperature\n",
    "print(\"=\" * 70)\n",
    "print(\"ABLATION STUDY 3: GENERATION TEMPERATURE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train one model first\n",
    "print(\"\\nTraining baseline model for temperature ablation...\")\n",
    "student = StudentModel(StudentConfig(\n",
    "    model_name=\"google/flan-t5-small\",\n",
    "    max_source_length=128,\n",
    "    max_target_length=64,\n",
    "    device=device\n",
    "))\n",
    "\n",
    "distillation_strategy = SequenceLevelDistillation(DistillationConfig(\n",
    "    ce_weight=1.0,\n",
    "    label_smoothing=0.1\n",
    "))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=student,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    distillation_strategy=distillation_strategy,\n",
    "    config=TrainingConfig(\n",
    "        num_epochs=3,\n",
    "        learning_rate=5e-5,\n",
    "        output_dir=\"../experiments/ablation_temperature_base\"\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"âœ“ Base model trained\\n\")\n",
    "\n",
    "# Test different temperatures\n",
    "temperatures = [0.5, 0.7, 1.0, 1.2]\n",
    "temperature_results = []\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\nTesting temperature = {temp}\")\n",
    "    \n",
    "    # Update student config\n",
    "    student.config.temperature = temp\n",
    "    \n",
    "    # Evaluate\n",
    "    evaluator = Evaluator(student, EvaluationConfig(\n",
    "        metrics_config=MetricsConfig(\n",
    "            compute_rouge=True,\n",
    "            compute_bertscore=False,\n",
    "            compute_faithfulness=True\n",
    "        ),\n",
    "        save_predictions=False,\n",
    "        output_dir=f\"../experiments/ablation_temp_{temp}_eval\"\n",
    "    ))\n",
    "    \n",
    "    results = evaluator.evaluate(val_loader, split_name=\"val\")\n",
    "    \n",
    "    temperature_results.append({\n",
    "        'temperature': temp,\n",
    "        'accuracy': results['metrics']['label_accuracy'],\n",
    "        'rouge1': results['metrics']['rouge1'],\n",
    "        'rougeL': results['metrics']['rougeL'],\n",
    "        'faithfulness': results['metrics']['faithfulness']\n",
    "    })\n",
    "    \n",
    "    print(f\"  Accuracy: {results['metrics']['label_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEMPERATURE ABLATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cc61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature results\n",
    "temp_df = pd.DataFrame(temperature_results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: All metrics\n",
    "for metric, color in zip(['accuracy', 'rouge1', 'rougeL', 'faithfulness'], \n",
    "                         ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']):\n",
    "    axes[0].plot(temp_df['temperature'], temp_df[metric], \n",
    "                 marker='o', linewidth=2, markersize=8, label=metric.upper(), color=color)\n",
    "\n",
    "axes[0].set_xlabel('Temperature')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Metrics vs Generation Temperature')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy zoom\n",
    "axes[1].plot(temp_df['temperature'], temp_df['accuracy'], \n",
    "             marker='o', linewidth=3, markersize=10, color='#e74c3c')\n",
    "axes[1].set_xlabel('Temperature')\n",
    "axes[1].set_ylabel('Label Accuracy')\n",
    "axes[1].set_title('Label Accuracy vs Temperature')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "for x, y in zip(temp_df['temperature'], temp_df['accuracy']):\n",
    "    axes[1].text(x, y + 0.005, f'{y:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.suptitle('Ablation Study: Generation Temperature Impact', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTemperature Results Summary:\")\n",
    "print(temp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63153a0",
   "metadata": {},
   "source": [
    "## 5. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all ablation results\n",
    "print(\"=\" * 70)\n",
    "print(\"ABLATION STUDIES SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ“Š LABEL SMOOTHING:\")\n",
    "best_smoothing = smoothing_df.loc[smoothing_df['accuracy'].idxmax()]\n",
    "print(f\"  Best value: {best_smoothing['smoothing']}\")\n",
    "print(f\"  Best accuracy: {best_smoothing['accuracy']:.4f}\")\n",
    "print(f\"  Recommendation: Use label_smoothing={best_smoothing['smoothing']} for final training\")\n",
    "\n",
    "print(\"\\nðŸ“Š TRAINING DATA SIZE:\")\n",
    "print(\"  Performance scaling:\")\n",
    "for _, row in datasize_df.iterrows():\n",
    "    print(f\"    {row['n_samples']:4d} samples â†’ Accuracy: {row['accuracy']:.4f}\")\n",
    "print(f\"  Recommendation: {'More data helps significantly' if datasize_df['accuracy'].iloc[-1] - datasize_df['accuracy'].iloc[0] > 0.1 else 'Diminishing returns after 50%'}\")\n",
    "\n",
    "print(\"\\nðŸ“Š GENERATION TEMPERATURE:\")\n",
    "best_temp = temp_df.loc[temp_df['accuracy'].idxmax()]\n",
    "print(f\"  Best value: {best_temp['temperature']}\")\n",
    "print(f\"  Best accuracy: {best_temp['accuracy']:.4f}\")\n",
    "print(f\"  Recommendation: Use temperature={best_temp['temperature']} for inference\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"1. Optimal label smoothing: {best_smoothing['smoothing']}\")\n",
    "print(f\"2. Data efficiency: {'High' if datasize_df['accuracy'].iloc[1] / datasize_df['accuracy'].iloc[-1] > 0.9 else 'Moderate'}\")\n",
    "print(f\"3. Temperature sensitivity: {'Low' if temp_df['accuracy'].std() < 0.02 else 'Moderate to High'}\")\n",
    "print(\"\\nðŸ’¡ Use these optimal hyperparameters for final model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to CSV for later analysis\n",
    "output_dir = Path(\"../experiments/ablation_studies\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "smoothing_df.to_csv(output_dir / \"label_smoothing_results.csv\", index=False)\n",
    "datasize_df.to_csv(output_dir / \"data_size_results.csv\", index=False)\n",
    "temp_df.to_csv(output_dir / \"temperature_results.csv\", index=False)\n",
    "\n",
    "print(f\"âœ“ All ablation results saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
