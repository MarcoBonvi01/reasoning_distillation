{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "21104051",
      "metadata": {},
      "source": [
        "# Baseline Training (No Distillation)\n",
        "This notebook trains the **same student model WITHOUT knowledge distillation** to serve as a baseline for comparison.\n",
        "\n",
        "### Training Setup:\n",
        "```\n",
        "Loss = α·CE(student, labels) + β·KL(student||teacher)\n",
        "     = 1.0·CE + 0.0·KL\n",
        "     = CE (standard supervised learning)\n",
        "```\n",
        "\n",
        "### Purpose:\n",
        "- Train student model with **β = 0.0** (no teacher guidance)\n",
        "- Use **identical hyperparameters** as notebook 06 (distillation training)\n",
        "- Provide a **fair baseline** to measure the value of knowledge distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f64a5135",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pprint import pprint\n",
        "import time\n",
        "\n",
        "from src.data.data_loader import TeacherDataLoader\n",
        "from src.data.preprocessor import ReasoningPreprocessor, PreprocessConfig\n",
        "from src.data.dataset import ESNLIDataset, create_dataloaders\n",
        "\n",
        "from src.models.student import StudentModel, StudentConfig\n",
        "from src.models.teacher import FlanT5Teacher, TeacherConfig\n",
        "\n",
        "from src.training.distillation import (\n",
        "    DistillationConfig,\n",
        "    TokenLevelDistillation,\n",
        ")\n",
        "\n",
        "from src.training.trainer import Trainer, TrainingConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "be5f81d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87d6aa73",
      "metadata": {},
      "source": [
        "## 1. Load Dataset\n",
        "\n",
        "Use the **same dataset configuration** as notebook 06 for fair comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8621bd1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.data.data_loader:Loading e-SNLI dataset from GitHub (OanaMariaCamburu/e-SNLI)...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "LOADING DATASET FOR BASELINE TRAINING\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bad1242d153341a4b51a12aa311ff7c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/90.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7009fcb184784a92b485de6beed9b024",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef71ba24bfa846698f502122a1798a54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/99.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d18b1323dd34f37922fdfba5fa1ddb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "855f9ae0681545a8a2ff8be61f5906ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/259999 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a22bc44ca8041de93a7a0ea25f3dbdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/289368 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e17f8b3a5295436a937e0eb216897fd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/7.50M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38c1f72549f247f7adb19555b7ac3596",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46c433cd9f134e41919e8429341a5a4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9842 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4794cf15ccb84088a8c8b1744f45c056",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/7.44M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f007e2bc67249a29e0eae2824b965fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fac439ddcf054cc8affcd460c97d7d65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9824 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.data.data_loader:✓ Loaded e-SNLI: train=549367, val=9842, test=9824\n",
            "INFO:src.data.data_loader:e-SNLI loaded successfully. Splits: ['train', 'validation', 'test']\n",
            "INFO:src.data.data_loader:Sample counts: [('train', 549367), ('validation', 9842), ('test', 9824)]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Train samples: 50000\n",
            "✓ Val samples: 5000\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "print(\"=\" * 70)\n",
        "print(\"LOADING DATASET FOR BASELINE TRAINING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "loader = TeacherDataLoader()\n",
        "esnli_data = loader.load_esnli()\n",
        "\n",
        "train_subset = esnli_data['train'].select(range(50000))\n",
        "val_subset = esnli_data['validation'].select(range(5000))\n",
        "\n",
        "print(f\"\\nTrain samples: {len(train_subset)}\")\n",
        "print(f\"Val samples: {len(val_subset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df90131e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.data.preprocessor:Loading tokenizer: google/flan-t5-small\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3acade4e626411385649055e17f8bb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99db4299c4ad4079ab577d38684b29d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54fbe9185e374e8d8b44d15721a6f13d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46c08aea5ff6444d85fb96f9e49dd226",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.data.dataset:Initialized ESNLIDataset with 50000 samples\n",
            "INFO:src.data.dataset:Initialized ESNLIDataset with 5000 samples\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train batches: 1563\n",
            "Val batches: 157\n"
          ]
        }
      ],
      "source": [
        "# Create datasets and dataloaders\n",
        "preprocess_config = PreprocessConfig(\n",
        "    model_name=\"google/flan-t5-small\", # Using small model for faster processing\n",
        "    max_source_length=128,\n",
        "    max_target_length=64\n",
        ")\n",
        "\n",
        "preprocessor = ReasoningPreprocessor(preprocess_config)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ESNLIDataset(train_subset, preprocessor, use_cache=True)\n",
        "val_dataset = ESNLIDataset(val_subset, preprocessor, use_cache=True)\n",
        "\n",
        "train_loader, val_loader = create_dataloaders(\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=4,\n",
        "    pad_token_id=preprocessor.tokenizer.pad_token_id\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac3da8d3",
      "metadata": {},
      "source": [
        "## 2. Load Teacher Model\n",
        "\n",
        "We still need to load the teacher model for the distillation interface, but with **β = 0.0**, the KL loss will be multiplied by zero, effectively disabling teacher guidance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db7bba1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.teacher:Initializing teacher model: google/flan-t5-xl\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "LOADING TEACHER MODEL (for interface only, β=0.0)\n",
            "======================================================================\n",
            "Loading google/flan-t5-xl...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51197478dfdd4b2f81f23a0328075bd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30f3ed9da9dd49908052ab2fa0eb1dc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "756ad13bc95748a89d669f82f69a3bd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99207537516e4d33a76b18227d799728",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3601897af7440c38dc2aa95bdb43935",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc377fbf61ec4098a2481569a3bdd162",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a7e2619f72c4db2be57e98c2a99e73a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3c52c45d97d4c4ab819492ea9afd464",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1e641aac8044c40a219b9ff5db51d07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07767e8987f944fe868ac4182ab62ee8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5a3ce28564d4643a7182ec6f74a840f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.teacher:Teacher model loaded on cuda with dtype torch.float16\n",
            "INFO:src.models.teacher:Teacher parameters: 2,849,757,184 (frozen)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Teacher loaded (will NOT be used for training, β=0.0)\n",
            "  Parameters: 2,849,757,184\n"
          ]
        }
      ],
      "source": [
        "# Load Teacher Model\n",
        "print(\"=\" * 70)\n",
        "print(\"LOADING TEACHER MODEL (for interface only, β=0.0)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "teacher_config = TeacherConfig(\n",
        "    model_name=\"google/flan-t5-xl\",\n",
        "    device=device,\n",
        "    use_fp16=True if device == \"cuda\" else False,\n",
        "    max_source_length=128,\n",
        "    max_target_length=64\n",
        ")\n",
        "\n",
        "print(f\"Loading {teacher_config.model_name}...\")\n",
        "teacher = FlanT5Teacher(teacher_config)\n",
        "\n",
        "print(f\"\\nTeacher loaded (will NOT be used for training, β=0.0)\")\n",
        "print(f\"  Parameters: {teacher.count_parameters():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0acfb50",
      "metadata": {},
      "source": [
        "## 3. Initialize Student Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda10689",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.student:Initializing student model: google/flan-t5-small\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "INITIALIZING STUDENT MODEL\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d3a51a65de945d1b8018658b3699624",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6c55aff93754e23a476dc5cabcc2713",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "223385b7e0ae4b679a4e6ea66980e922",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "INFO:src.models.student:Model loaded successfully on cuda\n",
            "INFO:src.models.student:Model parameters: 76,961,152\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Student loaded!\n",
            "  Parameters: 76,961,152\n",
            "  Memory: 293.58 MB\n"
          ]
        }
      ],
      "source": [
        "# Initialize Student Model - SAME config as notebook 06\n",
        "print(\"=\" * 70)\n",
        "print(\"INITIALIZING STUDENT MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "student_config = StudentConfig(\n",
        "    model_name=\"google/flan-t5-small\",\n",
        "    max_source_length=128,\n",
        "    max_target_length=64,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "student = StudentModel(student_config)\n",
        "\n",
        "print(f\"\\nStudent loaded!\")\n",
        "print(f\"  Parameters: {student.count_parameters():,}\")\n",
        "print(f\"  Memory: {student.get_memory_footprint()['total_mb']:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02763f92",
      "metadata": {},
      "source": [
        "## 4. Configure Baseline Training (β = 0.0)\n",
        "\n",
        "**KEY DIFFERENCE**: `distill_weight = 0.0` means NO knowledge distillation.\n",
        "\n",
        "```\n",
        "Loss = 1.0·CE + 0.0·KL = CE (standard supervised learning)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd921cf7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.training.distillation:Initialized DistillationLoss with config:\n",
            "INFO:src.training.distillation:  CE weight: 1.0\n",
            "INFO:src.training.distillation:  Distill weight: 0.0\n",
            "INFO:src.training.distillation:  Temperature: 2.0\n",
            "INFO:src.training.distillation:  Type: token_level\n",
            "INFO:src.training.distillation:Initialized TokenLevelDistillation with teacher model\n",
            "INFO:src.training.distillation:  α (CE weight): 1.0\n",
            "INFO:src.training.distillation:  β (Distill weight): 0.0\n",
            "INFO:src.training.distillation:  Temperature: 2.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CONFIGURING BASELINE TRAINING (β = 0.0)\n",
            "======================================================================\n",
            "\n",
            "✓ Baseline Training configured!\n",
            "  Loss = 1.0·CE + 0.0·KL\n",
            "  Loss = CE only (standard supervised learning)\n",
            "  Teacher guidance: DISABLED (β=0.0)\n"
          ]
        }
      ],
      "source": [
        "# Configure Baseline Training (NO DISTILLATION)\n",
        "print(\"=\" * 70)\n",
        "print(\"CONFIGURING BASELINE TRAINING (β = 0.0)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# BASELINE configuration: β = 0.0 (NO teacher guidance)\n",
        "baseline_distill_config = DistillationConfig(\n",
        "    ce_weight=1.0,        # α - Cross-entropy weight\n",
        "    distill_weight=0.0,   # β = 0.0 → NO KL divergence loss!\n",
        "    temperature=2.0,      # Not used when β=0.0\n",
        "    label_smoothing=0.0,\n",
        "    distillation_type=\"token_level\"\n",
        ")\n",
        "\n",
        "# Create distillation strategy (KL will be multiplied by 0)\n",
        "baseline_strategy = TokenLevelDistillation(\n",
        "    teacher_model=teacher,\n",
        "    config=baseline_distill_config\n",
        ")\n",
        "\n",
        "print(f\"\\nBaseline Training configured!\")\n",
        "print(f\"  Loss = {baseline_distill_config.ce_weight}·CE + {baseline_distill_config.distill_weight}·KL\")\n",
        "print(f\"  Loss = CE only (standard supervised learning)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05cb5aec",
      "metadata": {},
      "source": [
        "## 5. Initialize Trainer\n",
        "\n",
        "Use **IDENTICAL training hyperparameters** as notebook 06 for fair comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0d2c59",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.training.trainer:Training config saved to ../experiments/baseline/training_config.json\n",
            "INFO:src.training.trainer:Trainer initialized\n",
            "INFO:src.training.trainer:Output directory: ../experiments/baseline\n",
            "INFO:src.training.trainer:Total training steps: 10941\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "INITIALIZING TRAINER (SAME config as distillation training)\n",
            "======================================================================\n",
            "\n",
            "✓ Trainer initialized!\n",
            "  Total training steps: 10941\n",
            "  Training type: BASELINE (no distillation)\n",
            "  Loss: CE only (β=0.0)\n",
            "  Output: ../experiments/baseline\n"
          ]
        }
      ],
      "source": [
        "# Create training configuration - SAME as notebook 06\n",
        "print(\"=\" * 70)\n",
        "print(\"INITIALIZING TRAINER (SAME config as distillation training)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "training_config = TrainingConfig(\n",
        "    num_epochs=7,                          # SAME\n",
        "    learning_rate=5e-5,                    # SAME\n",
        "    warmup_steps=1200,                     # SAME\n",
        "    eval_steps=1000,                       # SAME\n",
        "    save_steps=1000,                       # SAME\n",
        "    logging_steps=50,                      # SAME\n",
        "    output_dir=\"../experiments/baseline\",  \n",
        "    eval_strategy=\"steps\",                 # SAME\n",
        "    save_strategy=\"steps\",                 # SAME\n",
        "    save_total_limit=3,                    # SAME\n",
        "    early_stopping_patience=5,             # SAME\n",
        "    early_stopping_threshold=0.001,        # SAME\n",
        "    lr_scheduler_type=\"cosine\",            # SAME\n",
        "    gradient_accumulation_steps=2,         # SAME\n",
        "    max_grad_norm=1.0,                     # SAME\n",
        "    fp16=False,                            # SAME\n",
        "    seed=42                                # SAME seed for reproducibility\n",
        ")\n",
        "\n",
        "# Create trainer with baseline strategy\n",
        "trainer = Trainer(\n",
        "    model=student,\n",
        "    train_dataloader=train_loader,\n",
        "    eval_dataloader=val_loader,\n",
        "    distillation_strategy=baseline_strategy,\n",
        "    config=training_config\n",
        ")\n",
        "\n",
        "print(\"\\nTrainer initialized!\")\n",
        "print(f\"  Total training steps: {len(train_loader) * training_config.num_epochs}\")\n",
        "print(f\"  Training type: BASELINE (no distillation)\")\n",
        "print(f\"  Loss: CE only (β=0.0)\")\n",
        "print(f\"  Output: {training_config.output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b85753b",
      "metadata": {},
      "source": [
        "## 6. Run Baseline Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dffe1305",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.training.trainer:======================================================================\n",
            "INFO:src.training.trainer:STARTING TRAINING\n",
            "INFO:src.training.trainer:======================================================================\n",
            "INFO:src.training.trainer:Epochs: 7\n",
            "INFO:src.training.trainer:Train batches per epoch: 1563\n",
            "INFO:src.training.trainer:Eval batches: 157\n",
            "INFO:src.training.trainer:\n",
            "======================================================================\n",
            "INFO:src.training.trainer:Epoch 1/7\n",
            "INFO:src.training.trainer:======================================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STARTING BASELINE TRAINING (NO DISTILLATION)\n",
            "======================================================================\n",
            "\n",
            "Student: google/flan-t5-small\n",
            "Loss: 1.0·CE + 0.0·KL\n",
            "Loss: CE only (standard supervised learning)\n",
            "Teacher guidance: DISABLED\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 0/1563 [00:02<?, ?it/s, loss=3.6748, lr=5.00e-06]INFO:src.training.trainer:Step 0 | ce_loss: 3.6748 | total_loss: 3.6748 | LR: 5.00e-06\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:42,  1.52it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:32,  4.78it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.85it/s]\u001b[A\n",
            "Evaluating:   5%|▌         | 8/157 [00:01<00:12, 11.55it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:10, 14.14it/s]\u001b[A\n",
            "Evaluating:   9%|▉         | 14/157 [00:01<00:08, 15.95it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:08, 17.23it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 20/157 [00:01<00:07, 18.12it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.76it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 26/157 [00:01<00:06, 19.17it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.47it/s]\u001b[A\n",
            "Evaluating:  20%|██        | 32/157 [00:02<00:06, 19.67it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.83it/s]\u001b[A\n",
            "Evaluating:  24%|██▍       | 38/157 [00:02<00:05, 19.96it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 20.02it/s]\u001b[A\n",
            "Evaluating:  28%|██▊       | 44/157 [00:02<00:05, 20.08it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:02<00:05, 20.09it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 50/157 [00:03<00:05, 20.14it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 20.14it/s]\u001b[A\n",
            "Evaluating:  36%|███▌      | 56/157 [00:03<00:05, 20.16it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:04, 20.18it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 62/157 [00:03<00:04, 20.17it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 20.17it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 68/157 [00:03<00:04, 20.16it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 20.17it/s]\u001b[A\n",
            "Evaluating:  47%|████▋     | 74/157 [00:04<00:04, 20.12it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:03, 20.13it/s]\u001b[A\n",
            "Evaluating:  51%|█████     | 80/157 [00:04<00:03, 20.14it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 20.10it/s]\u001b[A\n",
            "Evaluating:  55%|█████▍    | 86/157 [00:04<00:03, 20.12it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 20.15it/s]\u001b[A\n",
            "Evaluating:  59%|█████▊    | 92/157 [00:05<00:03, 20.17it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 20.17it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 98/157 [00:05<00:02, 20.18it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 20.17it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 104/157 [00:05<00:02, 20.16it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:05<00:02, 20.16it/s]\u001b[A\n",
            "Evaluating:  70%|███████   | 110/157 [00:06<00:02, 20.16it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 20.17it/s]\u001b[A\n",
            "Evaluating:  74%|███████▍  | 116/157 [00:06<00:02, 20.16it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 20.17it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 122/157 [00:06<00:01, 20.17it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 20.18it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 128/157 [00:06<00:01, 20.20it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 20.18it/s]\u001b[A\n",
            "Evaluating:  85%|████████▌ | 134/157 [00:07<00:01, 20.17it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:00, 20.19it/s]\u001b[A\n",
            "Evaluating:  89%|████████▉ | 140/157 [00:07<00:00, 20.21it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 20.20it/s]\u001b[A\n",
            "Evaluating:  93%|█████████▎| 146/157 [00:07<00:00, 20.19it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 20.18it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 152/157 [00:08<00:00, 20.19it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 18.25it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 0:\n",
            "INFO:src.training.trainer:  eval_loss: 3.6817\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-0\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-0\n",
            "INFO:src.models.student:Model saved successfully\n",
            "Epoch 1:   6%|▋         | 99/1563 [01:35<20:50,  1.17it/s, loss=2.7224, lr=6.88e-06] INFO:src.training.trainer:Step 50 | ce_loss: 2.7224 | total_loss: 2.7224 | LR: 6.88e-06\n",
            "Epoch 1:   6%|▋         | 100/1563 [01:36<20:56,  1.16it/s, loss=2.9226, lr=6.88e-06]INFO:src.training.trainer:Step 50 | ce_loss: 2.9226 | total_loss: 2.9226 | LR: 6.88e-06\n",
            "Epoch 1:  13%|█▎        | 199/1563 [03:01<19:30,  1.17it/s, loss=2.2909, lr=8.75e-06]INFO:src.training.trainer:Step 100 | ce_loss: 2.2909 | total_loss: 2.2909 | LR: 8.75e-06\n",
            "Epoch 1:  13%|█▎        | 200/1563 [03:02<19:36,  1.16it/s, loss=2.0440, lr=8.75e-06]INFO:src.training.trainer:Step 100 | ce_loss: 2.0440 | total_loss: 2.0440 | LR: 8.75e-06\n",
            "Epoch 1:  19%|█▉        | 299/1563 [04:27<18:05,  1.16it/s, loss=1.8632, lr=1.06e-05]INFO:src.training.trainer:Step 150 | ce_loss: 1.8632 | total_loss: 1.8632 | LR: 1.06e-05\n",
            "Epoch 1:  19%|█▉        | 300/1563 [04:28<18:11,  1.16it/s, loss=1.6995, lr=1.06e-05]INFO:src.training.trainer:Step 150 | ce_loss: 1.6995 | total_loss: 1.6995 | LR: 1.06e-05\n",
            "Epoch 1:  26%|██▌       | 399/1563 [05:54<16:40,  1.16it/s, loss=1.6296, lr=1.25e-05]INFO:src.training.trainer:Step 200 | ce_loss: 1.6296 | total_loss: 1.6296 | LR: 1.25e-05\n",
            "Epoch 1:  26%|██▌       | 400/1563 [05:54<16:45,  1.16it/s, loss=1.5820, lr=1.25e-05]INFO:src.training.trainer:Step 200 | ce_loss: 1.5820 | total_loss: 1.5820 | LR: 1.25e-05\n",
            "Epoch 1:  32%|███▏      | 499/1563 [07:20<15:13,  1.16it/s, loss=1.6902, lr=1.44e-05]INFO:src.training.trainer:Step 250 | ce_loss: 1.6902 | total_loss: 1.6902 | LR: 1.44e-05\n",
            "Epoch 1:  32%|███▏      | 500/1563 [07:20<15:18,  1.16it/s, loss=1.5697, lr=1.44e-05]INFO:src.training.trainer:Step 250 | ce_loss: 1.5697 | total_loss: 1.5697 | LR: 1.44e-05\n",
            "Epoch 1:  38%|███▊      | 599/1563 [08:46<13:48,  1.16it/s, loss=1.8102, lr=1.62e-05]INFO:src.training.trainer:Step 300 | ce_loss: 1.8102 | total_loss: 1.8102 | LR: 1.62e-05\n",
            "Epoch 1:  38%|███▊      | 600/1563 [08:47<13:52,  1.16it/s, loss=1.3286, lr=1.62e-05]INFO:src.training.trainer:Step 300 | ce_loss: 1.3286 | total_loss: 1.3286 | LR: 1.62e-05\n",
            "Epoch 1:  45%|████▍     | 699/1563 [10:12<12:21,  1.17it/s, loss=1.3581, lr=1.81e-05]INFO:src.training.trainer:Step 350 | ce_loss: 1.3581 | total_loss: 1.3581 | LR: 1.81e-05\n",
            "Epoch 1:  45%|████▍     | 700/1563 [10:13<12:24,  1.16it/s, loss=1.3407, lr=1.81e-05]INFO:src.training.trainer:Step 350 | ce_loss: 1.3407 | total_loss: 1.3407 | LR: 1.81e-05\n",
            "Epoch 1:  51%|█████     | 799/1563 [11:38<10:55,  1.17it/s, loss=1.5352, lr=2.00e-05]INFO:src.training.trainer:Step 400 | ce_loss: 1.5352 | total_loss: 1.5352 | LR: 2.00e-05\n",
            "Epoch 1:  51%|█████     | 800/1563 [11:39<10:58,  1.16it/s, loss=1.5505, lr=2.00e-05]INFO:src.training.trainer:Step 400 | ce_loss: 1.5505 | total_loss: 1.5505 | LR: 2.00e-05\n",
            "Epoch 1:  58%|█████▊    | 899/1563 [13:04<09:29,  1.16it/s, loss=1.5094, lr=2.19e-05]INFO:src.training.trainer:Step 450 | ce_loss: 1.5094 | total_loss: 1.5094 | LR: 2.19e-05\n",
            "Epoch 1:  58%|█████▊    | 900/1563 [13:05<09:32,  1.16it/s, loss=1.7842, lr=2.19e-05]INFO:src.training.trainer:Step 450 | ce_loss: 1.7842 | total_loss: 1.7842 | LR: 2.19e-05\n",
            "Epoch 1:  64%|██████▍   | 999/1563 [14:30<08:04,  1.16it/s, loss=1.5480, lr=2.37e-05]INFO:src.training.trainer:Step 500 | ce_loss: 1.5480 | total_loss: 1.5480 | LR: 2.37e-05\n",
            "Epoch 1:  64%|██████▍   | 1000/1563 [14:31<08:06,  1.16it/s, loss=1.4455, lr=2.37e-05]INFO:src.training.trainer:Step 500 | ce_loss: 1.4455 | total_loss: 1.4455 | LR: 2.37e-05\n",
            "Epoch 1:  70%|███████   | 1099/1563 [15:56<06:38,  1.16it/s, loss=1.4386, lr=2.56e-05]INFO:src.training.trainer:Step 550 | ce_loss: 1.4386 | total_loss: 1.4386 | LR: 2.56e-05\n",
            "Epoch 1:  70%|███████   | 1100/1563 [15:57<06:39,  1.16it/s, loss=1.3295, lr=2.56e-05]INFO:src.training.trainer:Step 550 | ce_loss: 1.3295 | total_loss: 1.3295 | LR: 2.56e-05\n",
            "Epoch 1:  77%|███████▋  | 1199/1563 [17:22<05:12,  1.16it/s, loss=1.3753, lr=2.75e-05]INFO:src.training.trainer:Step 600 | ce_loss: 1.3753 | total_loss: 1.3753 | LR: 2.75e-05\n",
            "Epoch 1:  77%|███████▋  | 1200/1563 [17:23<05:13,  1.16it/s, loss=1.3502, lr=2.75e-05]INFO:src.training.trainer:Step 600 | ce_loss: 1.3502 | total_loss: 1.3502 | LR: 2.75e-05\n",
            "Epoch 1:  83%|████████▎ | 1299/1563 [18:48<03:46,  1.17it/s, loss=1.5065, lr=2.94e-05]INFO:src.training.trainer:Step 650 | ce_loss: 1.5065 | total_loss: 1.5065 | LR: 2.94e-05\n",
            "Epoch 1:  83%|████████▎ | 1300/1563 [18:49<03:46,  1.16it/s, loss=1.4970, lr=2.94e-05]INFO:src.training.trainer:Step 650 | ce_loss: 1.4970 | total_loss: 1.4970 | LR: 2.94e-05\n",
            "Epoch 1:  90%|████████▉ | 1399/1563 [20:15<02:20,  1.17it/s, loss=1.4321, lr=3.12e-05]INFO:src.training.trainer:Step 700 | ce_loss: 1.4321 | total_loss: 1.4321 | LR: 3.12e-05\n",
            "Epoch 1:  90%|████████▉ | 1400/1563 [20:15<02:20,  1.16it/s, loss=1.6422, lr=3.12e-05]INFO:src.training.trainer:Step 700 | ce_loss: 1.6422 | total_loss: 1.6422 | LR: 3.12e-05\n",
            "Epoch 1:  96%|█████████▌| 1499/1563 [21:41<00:54,  1.17it/s, loss=1.3976, lr=3.31e-05]INFO:src.training.trainer:Step 750 | ce_loss: 1.3976 | total_loss: 1.3976 | LR: 3.31e-05\n",
            "Epoch 1:  96%|█████████▌| 1500/1563 [21:41<00:54,  1.16it/s, loss=1.1534, lr=3.31e-05]INFO:src.training.trainer:Step 750 | ce_loss: 1.1534 | total_loss: 1.1534 | LR: 3.31e-05\n",
            "Epoch 1: 100%|██████████| 1563/1563 [22:35<00:00,  1.15it/s, loss=1.3149, lr=3.43e-05]\n",
            "INFO:src.training.trainer:\n",
            "Epoch 1 metrics:\n",
            "INFO:src.training.trainer:  loss: 1.6901\n",
            "INFO:src.training.trainer:  ce_loss: 1.6901\n",
            "INFO:src.training.trainer:\n",
            "======================================================================\n",
            "INFO:src.training.trainer:Epoch 2/7\n",
            "INFO:src.training.trainer:======================================================================\n",
            "Epoch 2:   2%|▏         | 37/1563 [00:33<21:48,  1.17it/s, loss=1.5000, lr=3.50e-05]INFO:src.training.trainer:Step 800 | ce_loss: 1.5000 | total_loss: 1.5000 | LR: 3.50e-05\n",
            "Epoch 2:   2%|▏         | 38/1563 [00:34<21:55,  1.16it/s, loss=1.7424, lr=3.50e-05]INFO:src.training.trainer:Step 800 | ce_loss: 1.7424 | total_loss: 1.7424 | LR: 3.50e-05\n",
            "Epoch 2:   9%|▉         | 137/1563 [01:59<20:23,  1.17it/s, loss=1.2970, lr=3.69e-05]INFO:src.training.trainer:Step 850 | ce_loss: 1.2970 | total_loss: 1.2970 | LR: 3.69e-05\n",
            "Epoch 2:   9%|▉         | 138/1563 [02:00<20:29,  1.16it/s, loss=1.2105, lr=3.69e-05]INFO:src.training.trainer:Step 850 | ce_loss: 1.2105 | total_loss: 1.2105 | LR: 3.69e-05\n",
            "Epoch 2:  15%|█▌        | 237/1563 [03:25<18:57,  1.17it/s, loss=1.4544, lr=3.87e-05]INFO:src.training.trainer:Step 900 | ce_loss: 1.4544 | total_loss: 1.4544 | LR: 3.87e-05\n",
            "Epoch 2:  15%|█▌        | 238/1563 [03:26<19:03,  1.16it/s, loss=1.3685, lr=3.87e-05]INFO:src.training.trainer:Step 900 | ce_loss: 1.3685 | total_loss: 1.3685 | LR: 3.87e-05\n",
            "Epoch 2:  22%|██▏       | 337/1563 [04:51<17:32,  1.17it/s, loss=1.1427, lr=4.06e-05]INFO:src.training.trainer:Step 950 | ce_loss: 1.1427 | total_loss: 1.1427 | LR: 4.06e-05\n",
            "Epoch 2:  22%|██▏       | 338/1563 [04:52<17:37,  1.16it/s, loss=1.1923, lr=4.06e-05]INFO:src.training.trainer:Step 950 | ce_loss: 1.1923 | total_loss: 1.1923 | LR: 4.06e-05\n",
            "Epoch 2:  28%|██▊       | 437/1563 [06:17<16:06,  1.16it/s, loss=1.3225, lr=4.25e-05]INFO:src.training.trainer:Step 1000 | ce_loss: 1.3225 | total_loss: 1.3225 | LR: 4.25e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:39,  1.56it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:31,  4.88it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.93it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.58it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.78it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:10, 14.51it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:09, 15.87it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.87it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.63it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.20it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.59it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.86it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.07it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.22it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.31it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.36it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.42it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.45it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.50it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.53it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.52it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.54it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:03<00:05, 19.54it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.54it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.56it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.54it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.58it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.58it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.58it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.56it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.58it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.54it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.59it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.59it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.59it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.57it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:08<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.62it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.63it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.63it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.63it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.71it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 1000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.2309\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-1000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-1000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "Epoch 2:  28%|██▊       | 438/1563 [06:29<1:19:36,  4.25s/it, loss=1.3838, lr=4.25e-05]INFO:src.training.trainer:Step 1000 | ce_loss: 1.3838 | total_loss: 1.3838 | LR: 4.25e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:41,  1.53it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:31,  4.82it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.87it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.55it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.78it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:10, 14.55it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:09, 15.92it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.94it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.71it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.28it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.70it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.97it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.17it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.32it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.42it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.48it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.53it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.55it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.56it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.58it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.60it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.61it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.63it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:02<00:05, 19.62it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.63it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.63it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.65it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.63it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.63it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.60it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.63it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.64it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.63it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.62it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.62it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.62it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.62it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.62it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.63it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.62it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.62it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.62it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.62it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:07<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.62it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.63it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.64it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.81it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 1000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.2309\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-1000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-1000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "Epoch 2:  34%|███▍      | 537/1563 [08:04<14:40,  1.16it/s, loss=1.4402, lr=4.44e-05]  INFO:src.training.trainer:Step 1050 | ce_loss: 1.4402 | total_loss: 1.4402 | LR: 4.44e-05\n",
            "Epoch 2:  34%|███▍      | 538/1563 [08:05<14:44,  1.16it/s, loss=1.3702, lr=4.44e-05]INFO:src.training.trainer:Step 1050 | ce_loss: 1.3702 | total_loss: 1.3702 | LR: 4.44e-05\n",
            "Epoch 2:  41%|████      | 637/1563 [09:30<13:14,  1.16it/s, loss=1.4409, lr=4.62e-05]INFO:src.training.trainer:Step 1100 | ce_loss: 1.4409 | total_loss: 1.4409 | LR: 4.62e-05\n",
            "Epoch 2:  41%|████      | 638/1563 [09:31<13:18,  1.16it/s, loss=1.0920, lr=4.62e-05]INFO:src.training.trainer:Step 1100 | ce_loss: 1.0920 | total_loss: 1.0920 | LR: 4.62e-05\n",
            "Epoch 2:  47%|████▋     | 737/1563 [10:57<11:49,  1.16it/s, loss=1.4260, lr=4.81e-05]INFO:src.training.trainer:Step 1150 | ce_loss: 1.4260 | total_loss: 1.4260 | LR: 4.81e-05\n",
            "Epoch 2:  47%|████▋     | 738/1563 [10:57<11:52,  1.16it/s, loss=1.6434, lr=4.81e-05]INFO:src.training.trainer:Step 1150 | ce_loss: 1.6434 | total_loss: 1.6434 | LR: 4.81e-05\n",
            "Epoch 2:  54%|█████▎    | 837/1563 [12:23<10:23,  1.16it/s, loss=1.2602, lr=5.00e-05]INFO:src.training.trainer:Step 1200 | ce_loss: 1.2602 | total_loss: 1.2602 | LR: 5.00e-05\n",
            "Epoch 2:  54%|█████▎    | 838/1563 [12:24<10:25,  1.16it/s, loss=1.4280, lr=5.00e-05]INFO:src.training.trainer:Step 1200 | ce_loss: 1.4280 | total_loss: 1.4280 | LR: 5.00e-05\n",
            "Epoch 2:  60%|█████▉    | 937/1563 [13:49<08:57,  1.16it/s, loss=1.1380, lr=5.00e-05]INFO:src.training.trainer:Step 1250 | ce_loss: 1.1380 | total_loss: 1.1380 | LR: 5.00e-05\n",
            "Epoch 2:  60%|██████    | 938/1563 [13:50<08:59,  1.16it/s, loss=1.3865, lr=5.00e-05]INFO:src.training.trainer:Step 1250 | ce_loss: 1.3865 | total_loss: 1.3865 | LR: 5.00e-05\n",
            "Epoch 2:  66%|██████▋   | 1037/1563 [15:15<07:31,  1.16it/s, loss=1.4799, lr=5.00e-05]INFO:src.training.trainer:Step 1300 | ce_loss: 1.4799 | total_loss: 1.4799 | LR: 5.00e-05\n",
            "Epoch 2:  66%|██████▋   | 1038/1563 [15:16<07:33,  1.16it/s, loss=1.3675, lr=5.00e-05]INFO:src.training.trainer:Step 1300 | ce_loss: 1.3675 | total_loss: 1.3675 | LR: 5.00e-05\n",
            "Epoch 2:  73%|███████▎  | 1137/1563 [16:41<06:05,  1.17it/s, loss=1.3798, lr=5.00e-05]INFO:src.training.trainer:Step 1350 | ce_loss: 1.3798 | total_loss: 1.3798 | LR: 5.00e-05\n",
            "Epoch 2:  73%|███████▎  | 1138/1563 [16:42<06:06,  1.16it/s, loss=1.4471, lr=5.00e-05]INFO:src.training.trainer:Step 1350 | ce_loss: 1.4471 | total_loss: 1.4471 | LR: 5.00e-05\n",
            "Epoch 2:  79%|███████▉  | 1237/1563 [18:07<04:39,  1.17it/s, loss=1.2342, lr=4.99e-05]INFO:src.training.trainer:Step 1400 | ce_loss: 1.2342 | total_loss: 1.2342 | LR: 4.99e-05\n",
            "Epoch 2:  79%|███████▉  | 1238/1563 [18:08<04:40,  1.16it/s, loss=1.1899, lr=4.99e-05]INFO:src.training.trainer:Step 1400 | ce_loss: 1.1899 | total_loss: 1.1899 | LR: 4.99e-05\n",
            "Epoch 2:  86%|████████▌ | 1337/1563 [19:33<03:13,  1.17it/s, loss=1.3047, lr=4.99e-05]INFO:src.training.trainer:Step 1450 | ce_loss: 1.3047 | total_loss: 1.3047 | LR: 4.99e-05\n",
            "Epoch 2:  86%|████████▌ | 1338/1563 [19:34<03:14,  1.16it/s, loss=1.4108, lr=4.99e-05]INFO:src.training.trainer:Step 1450 | ce_loss: 1.4108 | total_loss: 1.4108 | LR: 4.99e-05\n",
            "Epoch 2:  92%|█████████▏| 1437/1563 [20:59<01:48,  1.17it/s, loss=1.3893, lr=4.99e-05]INFO:src.training.trainer:Step 1500 | ce_loss: 1.3893 | total_loss: 1.3893 | LR: 4.99e-05\n",
            "Epoch 2:  92%|█████████▏| 1438/1563 [21:00<01:47,  1.16it/s, loss=1.1945, lr=4.99e-05]INFO:src.training.trainer:Step 1500 | ce_loss: 1.1945 | total_loss: 1.1945 | LR: 4.99e-05\n",
            "Epoch 2:  98%|█████████▊| 1537/1563 [22:25<00:22,  1.17it/s, loss=1.3917, lr=4.98e-05]INFO:src.training.trainer:Step 1550 | ce_loss: 1.3917 | total_loss: 1.3917 | LR: 4.98e-05\n",
            "Epoch 2:  98%|█████████▊| 1538/1563 [22:26<00:21,  1.16it/s, loss=1.2364, lr=4.98e-05]INFO:src.training.trainer:Step 1550 | ce_loss: 1.2364 | total_loss: 1.2364 | LR: 4.98e-05\n",
            "Epoch 2: 100%|██████████| 1563/1563 [22:46<00:00,  1.14it/s, loss=1.4656, lr=4.98e-05]\n",
            "INFO:src.training.trainer:\n",
            "Epoch 2 metrics:\n",
            "INFO:src.training.trainer:  loss: 1.3688\n",
            "INFO:src.training.trainer:  ce_loss: 1.3688\n",
            "INFO:src.training.trainer:\n",
            "======================================================================\n",
            "INFO:src.training.trainer:Epoch 3/7\n",
            "INFO:src.training.trainer:======================================================================\n",
            "Epoch 3:   5%|▍         | 75/1563 [01:05<21:12,  1.17it/s, loss=1.4043, lr=4.98e-05]INFO:src.training.trainer:Step 1600 | ce_loss: 1.4043 | total_loss: 1.4043 | LR: 4.98e-05\n",
            "Epoch 3:   5%|▍         | 76/1563 [01:06<21:19,  1.16it/s, loss=1.2200, lr=4.98e-05]INFO:src.training.trainer:Step 1600 | ce_loss: 1.2200 | total_loss: 1.2200 | LR: 4.98e-05\n",
            "Epoch 3:  11%|█         | 175/1563 [02:31<19:47,  1.17it/s, loss=1.2042, lr=4.97e-05]INFO:src.training.trainer:Step 1650 | ce_loss: 1.2042 | total_loss: 1.2042 | LR: 4.97e-05\n",
            "Epoch 3:  11%|█▏        | 176/1563 [02:32<19:53,  1.16it/s, loss=1.5169, lr=4.97e-05]INFO:src.training.trainer:Step 1650 | ce_loss: 1.5169 | total_loss: 1.5169 | LR: 4.97e-05\n",
            "Epoch 3:  18%|█▊        | 275/1563 [03:57<18:21,  1.17it/s, loss=1.1716, lr=4.97e-05]INFO:src.training.trainer:Step 1700 | ce_loss: 1.1716 | total_loss: 1.1716 | LR: 4.97e-05\n",
            "Epoch 3:  18%|█▊        | 276/1563 [03:58<18:26,  1.16it/s, loss=1.3218, lr=4.97e-05]INFO:src.training.trainer:Step 1700 | ce_loss: 1.3218 | total_loss: 1.3218 | LR: 4.97e-05\n",
            "Epoch 3:  24%|██▍       | 375/1563 [05:23<16:56,  1.17it/s, loss=1.3038, lr=4.96e-05]INFO:src.training.trainer:Step 1750 | ce_loss: 1.3038 | total_loss: 1.3038 | LR: 4.96e-05\n",
            "Epoch 3:  24%|██▍       | 376/1563 [05:23<17:01,  1.16it/s, loss=1.4637, lr=4.96e-05]INFO:src.training.trainer:Step 1750 | ce_loss: 1.4637 | total_loss: 1.4637 | LR: 4.96e-05\n",
            "Epoch 3:  30%|███       | 475/1563 [06:48<15:31,  1.17it/s, loss=1.4530, lr=4.95e-05]INFO:src.training.trainer:Step 1800 | ce_loss: 1.4530 | total_loss: 1.4530 | LR: 4.95e-05\n",
            "Epoch 3:  30%|███       | 476/1563 [06:49<15:35,  1.16it/s, loss=1.3176, lr=4.95e-05]INFO:src.training.trainer:Step 1800 | ce_loss: 1.3176 | total_loss: 1.3176 | LR: 4.95e-05\n",
            "Epoch 3:  37%|███▋      | 575/1563 [08:14<14:04,  1.17it/s, loss=1.2016, lr=4.95e-05]INFO:src.training.trainer:Step 1850 | ce_loss: 1.2016 | total_loss: 1.2016 | LR: 4.95e-05\n",
            "Epoch 3:  37%|███▋      | 576/1563 [08:15<14:08,  1.16it/s, loss=1.1289, lr=4.95e-05]INFO:src.training.trainer:Step 1850 | ce_loss: 1.1289 | total_loss: 1.1289 | LR: 4.95e-05\n",
            "Epoch 3:  43%|████▎     | 675/1563 [09:40<12:39,  1.17it/s, loss=1.2227, lr=4.94e-05]INFO:src.training.trainer:Step 1900 | ce_loss: 1.2227 | total_loss: 1.2227 | LR: 4.94e-05\n",
            "Epoch 3:  43%|████▎     | 676/1563 [09:41<12:42,  1.16it/s, loss=1.3826, lr=4.94e-05]INFO:src.training.trainer:Step 1900 | ce_loss: 1.3826 | total_loss: 1.3826 | LR: 4.94e-05\n",
            "Epoch 3:  50%|████▉     | 775/1563 [11:06<11:14,  1.17it/s, loss=1.3493, lr=4.93e-05]INFO:src.training.trainer:Step 1950 | ce_loss: 1.3493 | total_loss: 1.3493 | LR: 4.93e-05\n",
            "Epoch 3:  50%|████▉     | 776/1563 [11:07<11:17,  1.16it/s, loss=1.2420, lr=4.93e-05]INFO:src.training.trainer:Step 1950 | ce_loss: 1.2420 | total_loss: 1.2420 | LR: 4.93e-05\n",
            "Epoch 3:  56%|█████▌    | 875/1563 [12:32<09:49,  1.17it/s, loss=1.6353, lr=4.92e-05]INFO:src.training.trainer:Step 2000 | ce_loss: 1.6353 | total_loss: 1.6353 | LR: 4.92e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:36,  1.62it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:30,  5.04it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:18,  8.14it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:13, 10.81it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.99it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:09, 14.70it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:08, 16.00it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.99it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.71it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.23it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.60it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.86it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.05it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.19it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.31it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.36it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.41it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.44it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.46it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.47it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.48it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.51it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.51it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:02<00:05, 19.51it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.52it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.51it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:05, 19.52it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.51it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.52it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.52it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.52it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.54it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.54it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.52it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.54it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.55it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.56it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.54it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.53it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.53it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.54it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.52it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.50it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.53it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.50it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.50it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.52it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.54it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.53it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.54it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.54it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.55it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.53it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.50it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.52it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.53it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.52it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.52it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.53it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.53it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.54it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.52it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.56it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:07<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.54it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.57it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.76it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 2000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1852\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-2000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-2000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "Epoch 3:  56%|█████▌    | 876/1563 [12:44<48:36,  4.24s/it, loss=1.3147, lr=4.92e-05]INFO:src.training.trainer:Step 2000 | ce_loss: 1.3147 | total_loss: 1.3147 | LR: 4.92e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:38,  1.58it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:31,  4.92it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.99it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.65it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.86it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:10, 14.60it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:09, 15.96it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.97it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.72it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.26it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.66it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.95it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.12it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.26it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.36it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.41it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.43it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.48it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.51it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.57it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:02<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.61it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.60it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.60it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.59it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.60it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.60it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.60it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.63it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.65it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.63it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.64it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.63it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.63it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.63it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.63it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.63it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.62it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.62it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.59it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.63it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.55it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.57it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:07<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.56it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.76it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 2000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1852\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-2000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-2000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "Epoch 3:  62%|██████▏   | 975/1563 [14:19<08:24,  1.17it/s, loss=1.0996, lr=4.91e-05]  INFO:src.training.trainer:Step 2050 | ce_loss: 1.0996 | total_loss: 1.0996 | LR: 4.91e-05\n",
            "Epoch 3:  62%|██████▏   | 976/1563 [14:20<08:26,  1.16it/s, loss=1.2820, lr=4.91e-05]INFO:src.training.trainer:Step 2050 | ce_loss: 1.2820 | total_loss: 1.2820 | LR: 4.91e-05\n",
            "Epoch 3:  69%|██████▉   | 1075/1563 [15:45<06:59,  1.16it/s, loss=1.2013, lr=4.90e-05]INFO:src.training.trainer:Step 2100 | ce_loss: 1.2013 | total_loss: 1.2013 | LR: 4.90e-05\n",
            "Epoch 3:  69%|██████▉   | 1076/1563 [15:46<07:00,  1.16it/s, loss=1.3853, lr=4.90e-05]INFO:src.training.trainer:Step 2100 | ce_loss: 1.3853 | total_loss: 1.3853 | LR: 4.90e-05\n",
            "Epoch 3:  75%|███████▌  | 1175/1563 [17:11<05:33,  1.16it/s, loss=1.2091, lr=4.88e-05]INFO:src.training.trainer:Step 2150 | ce_loss: 1.2091 | total_loss: 1.2091 | LR: 4.88e-05\n",
            "Epoch 3:  75%|███████▌  | 1176/1563 [17:12<05:34,  1.16it/s, loss=1.4747, lr=4.88e-05]INFO:src.training.trainer:Step 2150 | ce_loss: 1.4747 | total_loss: 1.4747 | LR: 4.88e-05\n",
            "Epoch 3:  82%|████████▏ | 1275/1563 [18:37<04:07,  1.17it/s, loss=1.1744, lr=4.87e-05]INFO:src.training.trainer:Step 2200 | ce_loss: 1.1744 | total_loss: 1.1744 | LR: 4.87e-05\n",
            "Epoch 3:  82%|████████▏ | 1276/1563 [18:38<04:07,  1.16it/s, loss=1.2325, lr=4.87e-05]INFO:src.training.trainer:Step 2200 | ce_loss: 1.2325 | total_loss: 1.2325 | LR: 4.87e-05\n",
            "Epoch 3:  88%|████████▊ | 1375/1563 [20:03<02:41,  1.16it/s, loss=1.1483, lr=4.86e-05]INFO:src.training.trainer:Step 2250 | ce_loss: 1.1483 | total_loss: 1.1483 | LR: 4.86e-05\n",
            "Epoch 3:  88%|████████▊ | 1376/1563 [20:04<02:41,  1.16it/s, loss=1.2690, lr=4.86e-05]INFO:src.training.trainer:Step 2250 | ce_loss: 1.2690 | total_loss: 1.2690 | LR: 4.86e-05\n",
            "Epoch 3:  94%|█████████▍| 1475/1563 [21:29<01:15,  1.17it/s, loss=1.1176, lr=4.84e-05]INFO:src.training.trainer:Step 2300 | ce_loss: 1.1176 | total_loss: 1.1176 | LR: 4.84e-05\n",
            "Epoch 3:  94%|█████████▍| 1476/1563 [21:30<01:15,  1.16it/s, loss=1.3065, lr=4.84e-05]INFO:src.training.trainer:Step 2300 | ce_loss: 1.3065 | total_loss: 1.3065 | LR: 4.84e-05\n",
            "Epoch 3: 100%|██████████| 1563/1563 [22:44<00:00,  1.15it/s, loss=1.2381, lr=4.83e-05]\n",
            "INFO:src.training.trainer:\n",
            "Epoch 3 metrics:\n",
            "INFO:src.training.trainer:  loss: 1.3041\n",
            "INFO:src.training.trainer:  ce_loss: 1.3041\n",
            "INFO:src.training.trainer:\n",
            "======================================================================\n",
            "INFO:src.training.trainer:Epoch 4/7\n",
            "INFO:src.training.trainer:======================================================================\n",
            "Epoch 4:   1%|          | 13/1563 [00:12<22:14,  1.16it/s, loss=1.3759, lr=4.83e-05]INFO:src.training.trainer:Step 2350 | ce_loss: 1.3759 | total_loss: 1.3759 | LR: 4.83e-05\n",
            "Epoch 4:   1%|          | 14/1563 [00:13<22:19,  1.16it/s, loss=1.1605, lr=4.83e-05]INFO:src.training.trainer:Step 2350 | ce_loss: 1.1605 | total_loss: 1.1605 | LR: 4.83e-05\n",
            "Epoch 4:   7%|▋         | 113/1563 [01:38<20:44,  1.17it/s, loss=1.2620, lr=4.82e-05]INFO:src.training.trainer:Step 2400 | ce_loss: 1.2620 | total_loss: 1.2620 | LR: 4.82e-05\n",
            "Epoch 4:   7%|▋         | 114/1563 [01:39<20:50,  1.16it/s, loss=1.3170, lr=4.82e-05]INFO:src.training.trainer:Step 2400 | ce_loss: 1.3170 | total_loss: 1.3170 | LR: 4.82e-05\n",
            "Epoch 4:  14%|█▎        | 213/1563 [03:04<19:19,  1.16it/s, loss=1.5209, lr=4.80e-05]INFO:src.training.trainer:Step 2450 | ce_loss: 1.5209 | total_loss: 1.5209 | LR: 4.80e-05\n",
            "Epoch 4:  14%|█▎        | 214/1563 [03:05<19:24,  1.16it/s, loss=1.3018, lr=4.80e-05]INFO:src.training.trainer:Step 2450 | ce_loss: 1.3018 | total_loss: 1.3018 | LR: 4.80e-05\n",
            "Epoch 4:  20%|██        | 313/1563 [04:30<17:53,  1.16it/s, loss=1.2786, lr=4.78e-05]INFO:src.training.trainer:Step 2500 | ce_loss: 1.2786 | total_loss: 1.2786 | LR: 4.78e-05\n",
            "Epoch 4:  20%|██        | 314/1563 [04:31<17:59,  1.16it/s, loss=1.1361, lr=4.78e-05]INFO:src.training.trainer:Step 2500 | ce_loss: 1.1361 | total_loss: 1.1361 | LR: 4.78e-05\n",
            "Epoch 4:  26%|██▋       | 413/1563 [05:57<16:27,  1.16it/s, loss=1.4198, lr=4.77e-05]INFO:src.training.trainer:Step 2550 | ce_loss: 1.4198 | total_loss: 1.4198 | LR: 4.77e-05\n",
            "Epoch 4:  26%|██▋       | 414/1563 [05:57<16:32,  1.16it/s, loss=1.1654, lr=4.77e-05]INFO:src.training.trainer:Step 2550 | ce_loss: 1.1654 | total_loss: 1.1654 | LR: 4.77e-05\n",
            "Epoch 4:  33%|███▎      | 513/1563 [07:23<15:03,  1.16it/s, loss=1.2623, lr=4.75e-05]INFO:src.training.trainer:Step 2600 | ce_loss: 1.2623 | total_loss: 1.2623 | LR: 4.75e-05\n",
            "Epoch 4:  33%|███▎      | 514/1563 [07:24<15:07,  1.16it/s, loss=1.2608, lr=4.75e-05]INFO:src.training.trainer:Step 2600 | ce_loss: 1.2608 | total_loss: 1.2608 | LR: 4.75e-05\n",
            "Epoch 4:  39%|███▉      | 613/1563 [08:49<13:35,  1.16it/s, loss=1.2024, lr=4.73e-05]INFO:src.training.trainer:Step 2650 | ce_loss: 1.2024 | total_loss: 1.2024 | LR: 4.73e-05\n",
            "Epoch 4:  39%|███▉      | 614/1563 [08:50<13:39,  1.16it/s, loss=1.3028, lr=4.73e-05]INFO:src.training.trainer:Step 2650 | ce_loss: 1.3028 | total_loss: 1.3028 | LR: 4.73e-05\n",
            "Epoch 4:  46%|████▌     | 713/1563 [10:15<12:10,  1.16it/s, loss=1.1433, lr=4.71e-05]INFO:src.training.trainer:Step 2700 | ce_loss: 1.1433 | total_loss: 1.1433 | LR: 4.71e-05\n",
            "Epoch 4:  46%|████▌     | 714/1563 [10:16<12:13,  1.16it/s, loss=1.2668, lr=4.71e-05]INFO:src.training.trainer:Step 2700 | ce_loss: 1.2668 | total_loss: 1.2668 | LR: 4.71e-05\n",
            "Epoch 4:  52%|█████▏    | 813/1563 [11:41<10:44,  1.16it/s, loss=1.2107, lr=4.69e-05]INFO:src.training.trainer:Step 2750 | ce_loss: 1.2107 | total_loss: 1.2107 | LR: 4.69e-05\n",
            "Epoch 4:  52%|█████▏    | 814/1563 [11:42<10:47,  1.16it/s, loss=1.4751, lr=4.69e-05]INFO:src.training.trainer:Step 2750 | ce_loss: 1.4751 | total_loss: 1.4751 | LR: 4.69e-05\n",
            "Epoch 4:  58%|█████▊    | 913/1563 [13:07<09:17,  1.16it/s, loss=1.3697, lr=4.67e-05]INFO:src.training.trainer:Step 2800 | ce_loss: 1.3697 | total_loss: 1.3697 | LR: 4.67e-05\n",
            "Epoch 4:  58%|█████▊    | 914/1563 [13:08<09:20,  1.16it/s, loss=1.3455, lr=4.67e-05]INFO:src.training.trainer:Step 2800 | ce_loss: 1.3455 | total_loss: 1.3455 | LR: 4.67e-05\n",
            "Epoch 4:  65%|██████▍   | 1013/1563 [14:33<07:52,  1.16it/s, loss=1.1496, lr=4.65e-05]INFO:src.training.trainer:Step 2850 | ce_loss: 1.1496 | total_loss: 1.1496 | LR: 4.65e-05\n",
            "Epoch 4:  65%|██████▍   | 1014/1563 [14:34<07:53,  1.16it/s, loss=1.1089, lr=4.65e-05]INFO:src.training.trainer:Step 2850 | ce_loss: 1.1089 | total_loss: 1.1089 | LR: 4.65e-05\n",
            "Epoch 4:  71%|███████   | 1113/1563 [15:59<06:26,  1.16it/s, loss=1.3423, lr=4.63e-05]INFO:src.training.trainer:Step 2900 | ce_loss: 1.3423 | total_loss: 1.3423 | LR: 4.63e-05\n",
            "Epoch 4:  71%|███████▏  | 1114/1563 [16:00<06:27,  1.16it/s, loss=1.2943, lr=4.63e-05]INFO:src.training.trainer:Step 2900 | ce_loss: 1.2943 | total_loss: 1.2943 | LR: 4.63e-05\n",
            "Epoch 4:  78%|███████▊  | 1213/1563 [17:25<05:00,  1.16it/s, loss=1.3700, lr=4.61e-05]INFO:src.training.trainer:Step 2950 | ce_loss: 1.3700 | total_loss: 1.3700 | LR: 4.61e-05\n",
            "Epoch 4:  78%|███████▊  | 1214/1563 [17:26<05:01,  1.16it/s, loss=1.1988, lr=4.61e-05]INFO:src.training.trainer:Step 2950 | ce_loss: 1.1988 | total_loss: 1.1988 | LR: 4.61e-05\n",
            "Epoch 4:  84%|████████▍ | 1313/1563 [18:52<03:34,  1.16it/s, loss=1.1978, lr=4.59e-05]INFO:src.training.trainer:Step 3000 | ce_loss: 1.1978 | total_loss: 1.1978 | LR: 4.59e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:41,  1.54it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:31,  4.84it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.89it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.54it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.75it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:10, 14.50it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:09, 15.86it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.89it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.66it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.20it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.59it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.84it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.04it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.17it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.24it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.33it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.38it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.42it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.46it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.42it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.48it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:03<00:05, 19.56it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.60it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.59it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.55it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.50it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:05, 19.56it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.52it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.53it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.55it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.58it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.54it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.54it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.54it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.56it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.58it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.58it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.54it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.58it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.58it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.54it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.55it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:08<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.57it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.54it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.57it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.69it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 3000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1631\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-3000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-3000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Removing old checkpoint: ../experiments/baseline/checkpoint-0\n",
            "Epoch 4:  84%|████████▍ | 1314/1563 [19:04<17:32,  4.23s/it, loss=1.2139, lr=4.59e-05]INFO:src.training.trainer:Step 3000 | ce_loss: 1.2139 | total_loss: 1.2139 | LR: 4.59e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:39,  1.58it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:31,  4.91it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.99it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.67it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.88it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:09, 14.65it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:08, 16.00it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 17.01it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.74it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.26it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.64it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.90it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.11it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.26it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.33it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.41it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.47it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.51it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.52it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.53it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.55it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.59it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.60it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:02<00:05, 19.61it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.62it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.63it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.64it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.64it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.65it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:04, 19.63it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.60it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.58it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.58it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.62it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.62it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.62it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.62it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.58it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.59it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.60it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.64it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.63it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.62it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.62it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.57it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.54it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:07<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.57it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.59it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.82it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 3000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1631\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-3000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-3000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "Epoch 4:  90%|█████████ | 1413/1563 [20:39<02:08,  1.16it/s, loss=1.1159, lr=4.57e-05]INFO:src.training.trainer:Step 3050 | ce_loss: 1.1159 | total_loss: 1.1159 | LR: 4.57e-05\n",
            "Epoch 4:  90%|█████████ | 1414/1563 [20:40<02:08,  1.16it/s, loss=1.4020, lr=4.57e-05]INFO:src.training.trainer:Step 3050 | ce_loss: 1.4020 | total_loss: 1.4020 | LR: 4.57e-05\n",
            "Epoch 4:  97%|█████████▋| 1513/1563 [22:05<00:42,  1.16it/s, loss=1.1330, lr=4.55e-05]INFO:src.training.trainer:Step 3100 | ce_loss: 1.1330 | total_loss: 1.1330 | LR: 4.55e-05\n",
            "Epoch 4:  97%|█████████▋| 1514/1563 [22:06<00:42,  1.16it/s, loss=1.1290, lr=4.55e-05]INFO:src.training.trainer:Step 3100 | ce_loss: 1.1290 | total_loss: 1.1290 | LR: 4.55e-05\n",
            "Epoch 4: 100%|██████████| 1563/1563 [22:47<00:00,  1.14it/s, loss=1.2554, lr=4.53e-05]\n",
            "INFO:src.training.trainer:\n",
            "Epoch 4 metrics:\n",
            "INFO:src.training.trainer:  loss: 1.2646\n",
            "INFO:src.training.trainer:  ce_loss: 1.2646\n",
            "INFO:src.training.trainer:\n",
            "======================================================================\n",
            "INFO:src.training.trainer:Epoch 5/7\n",
            "INFO:src.training.trainer:======================================================================\n",
            "Epoch 5:   3%|▎         | 51/1563 [00:45<21:39,  1.16it/s, loss=1.3358, lr=4.52e-05]INFO:src.training.trainer:Step 3150 | ce_loss: 1.3358 | total_loss: 1.3358 | LR: 4.52e-05\n",
            "Epoch 5:   3%|▎         | 52/1563 [00:46<21:46,  1.16it/s, loss=1.3724, lr=4.52e-05]INFO:src.training.trainer:Step 3150 | ce_loss: 1.3724 | total_loss: 1.3724 | LR: 4.52e-05\n",
            "Epoch 5:  10%|▉         | 151/1563 [02:11<20:13,  1.16it/s, loss=1.2650, lr=4.50e-05]INFO:src.training.trainer:Step 3200 | ce_loss: 1.2650 | total_loss: 1.2650 | LR: 4.50e-05\n",
            "Epoch 5:  10%|▉         | 152/1563 [02:12<20:19,  1.16it/s, loss=1.2514, lr=4.50e-05]INFO:src.training.trainer:Step 3200 | ce_loss: 1.2514 | total_loss: 1.2514 | LR: 4.50e-05\n",
            "Epoch 5:  16%|█▌        | 251/1563 [03:37<18:45,  1.17it/s, loss=1.1620, lr=4.47e-05]INFO:src.training.trainer:Step 3250 | ce_loss: 1.1620 | total_loss: 1.1620 | LR: 4.47e-05\n",
            "Epoch 5:  16%|█▌        | 252/1563 [03:38<18:51,  1.16it/s, loss=1.1822, lr=4.47e-05]INFO:src.training.trainer:Step 3250 | ce_loss: 1.1822 | total_loss: 1.1822 | LR: 4.47e-05\n",
            "Epoch 5:  22%|██▏       | 351/1563 [05:03<17:20,  1.16it/s, loss=1.1978, lr=4.45e-05]INFO:src.training.trainer:Step 3300 | ce_loss: 1.1978 | total_loss: 1.1978 | LR: 4.45e-05\n",
            "Epoch 5:  23%|██▎       | 352/1563 [05:04<17:25,  1.16it/s, loss=1.4502, lr=4.45e-05]INFO:src.training.trainer:Step 3300 | ce_loss: 1.4502 | total_loss: 1.4502 | LR: 4.45e-05\n",
            "Epoch 5:  29%|██▉       | 451/1563 [06:29<15:53,  1.17it/s, loss=1.2242, lr=4.42e-05]INFO:src.training.trainer:Step 3350 | ce_loss: 1.2242 | total_loss: 1.2242 | LR: 4.42e-05\n",
            "Epoch 5:  29%|██▉       | 452/1563 [06:30<15:58,  1.16it/s, loss=1.2459, lr=4.42e-05]INFO:src.training.trainer:Step 3350 | ce_loss: 1.2459 | total_loss: 1.2459 | LR: 4.42e-05\n",
            "Epoch 5:  35%|███▌      | 551/1563 [07:55<14:28,  1.17it/s, loss=1.3662, lr=4.40e-05]INFO:src.training.trainer:Step 3400 | ce_loss: 1.3662 | total_loss: 1.3662 | LR: 4.40e-05\n",
            "Epoch 5:  35%|███▌      | 552/1563 [07:56<14:32,  1.16it/s, loss=1.3939, lr=4.40e-05]INFO:src.training.trainer:Step 3400 | ce_loss: 1.3939 | total_loss: 1.3939 | LR: 4.40e-05\n",
            "Epoch 5:  42%|████▏     | 651/1563 [09:21<13:02,  1.16it/s, loss=1.2249, lr=4.37e-05]INFO:src.training.trainer:Step 3450 | ce_loss: 1.2249 | total_loss: 1.2249 | LR: 4.37e-05\n",
            "Epoch 5:  42%|████▏     | 652/1563 [09:22<13:06,  1.16it/s, loss=1.3121, lr=4.37e-05]INFO:src.training.trainer:Step 3450 | ce_loss: 1.3121 | total_loss: 1.3121 | LR: 4.37e-05\n",
            "Epoch 5:  48%|████▊     | 751/1563 [10:47<11:37,  1.16it/s, loss=1.3744, lr=4.34e-05]INFO:src.training.trainer:Step 3500 | ce_loss: 1.3744 | total_loss: 1.3744 | LR: 4.34e-05\n",
            "Epoch 5:  48%|████▊     | 752/1563 [10:48<11:40,  1.16it/s, loss=1.1590, lr=4.34e-05]INFO:src.training.trainer:Step 3500 | ce_loss: 1.1590 | total_loss: 1.1590 | LR: 4.34e-05\n",
            "Epoch 5:  54%|█████▍    | 851/1563 [12:14<10:11,  1.16it/s, loss=1.1639, lr=4.32e-05]INFO:src.training.trainer:Step 3550 | ce_loss: 1.1639 | total_loss: 1.1639 | LR: 4.32e-05\n",
            "Epoch 5:  55%|█████▍    | 852/1563 [12:14<10:14,  1.16it/s, loss=1.0904, lr=4.32e-05]INFO:src.training.trainer:Step 3550 | ce_loss: 1.0904 | total_loss: 1.0904 | LR: 4.32e-05\n",
            "Epoch 5:  61%|██████    | 951/1563 [13:40<08:45,  1.16it/s, loss=1.1386, lr=4.29e-05]INFO:src.training.trainer:Step 3600 | ce_loss: 1.1386 | total_loss: 1.1386 | LR: 4.29e-05\n",
            "Epoch 5:  61%|██████    | 952/1563 [13:41<08:47,  1.16it/s, loss=1.2958, lr=4.29e-05]INFO:src.training.trainer:Step 3600 | ce_loss: 1.2958 | total_loss: 1.2958 | LR: 4.29e-05\n",
            "Epoch 5:  67%|██████▋   | 1051/1563 [15:06<07:19,  1.16it/s, loss=1.3642, lr=4.26e-05]INFO:src.training.trainer:Step 3650 | ce_loss: 1.3642 | total_loss: 1.3642 | LR: 4.26e-05\n",
            "Epoch 5:  67%|██████▋   | 1052/1563 [15:07<07:21,  1.16it/s, loss=1.2893, lr=4.26e-05]INFO:src.training.trainer:Step 3650 | ce_loss: 1.2893 | total_loss: 1.2893 | LR: 4.26e-05\n",
            "Epoch 5:  74%|███████▎  | 1151/1563 [16:32<05:53,  1.17it/s, loss=1.3580, lr=4.23e-05]INFO:src.training.trainer:Step 3700 | ce_loss: 1.3580 | total_loss: 1.3580 | LR: 4.23e-05\n",
            "Epoch 5:  74%|███████▎  | 1152/1563 [16:33<05:54,  1.16it/s, loss=1.0934, lr=4.23e-05]INFO:src.training.trainer:Step 3700 | ce_loss: 1.0934 | total_loss: 1.0934 | LR: 4.23e-05\n",
            "Epoch 5:  80%|████████  | 1251/1563 [17:58<04:27,  1.17it/s, loss=1.5039, lr=4.20e-05]INFO:src.training.trainer:Step 3750 | ce_loss: 1.5039 | total_loss: 1.5039 | LR: 4.20e-05\n",
            "Epoch 5:  80%|████████  | 1252/1563 [17:59<04:28,  1.16it/s, loss=1.1775, lr=4.20e-05]INFO:src.training.trainer:Step 3750 | ce_loss: 1.1775 | total_loss: 1.1775 | LR: 4.20e-05\n",
            "Epoch 5:  86%|████████▋ | 1351/1563 [19:24<03:01,  1.17it/s, loss=0.9746, lr=4.17e-05]INFO:src.training.trainer:Step 3800 | ce_loss: 0.9746 | total_loss: 0.9746 | LR: 4.17e-05\n",
            "Epoch 5:  87%|████████▋ | 1352/1563 [19:25<03:02,  1.16it/s, loss=1.0982, lr=4.17e-05]INFO:src.training.trainer:Step 3800 | ce_loss: 1.0982 | total_loss: 1.0982 | LR: 4.17e-05\n",
            "Epoch 5:  93%|█████████▎| 1451/1563 [20:50<01:36,  1.17it/s, loss=1.4297, lr=4.14e-05]INFO:src.training.trainer:Step 3850 | ce_loss: 1.4297 | total_loss: 1.4297 | LR: 4.14e-05\n",
            "Epoch 5:  93%|█████████▎| 1452/1563 [20:51<01:35,  1.16it/s, loss=1.1897, lr=4.14e-05]INFO:src.training.trainer:Step 3850 | ce_loss: 1.1897 | total_loss: 1.1897 | LR: 4.14e-05\n",
            "Epoch 5:  99%|█████████▉| 1551/1563 [22:16<00:10,  1.17it/s, loss=1.4395, lr=4.11e-05]INFO:src.training.trainer:Step 3900 | ce_loss: 1.4395 | total_loss: 1.4395 | LR: 4.11e-05\n",
            "Epoch 5:  99%|█████████▉| 1552/1563 [22:17<00:09,  1.16it/s, loss=1.4104, lr=4.11e-05]INFO:src.training.trainer:Step 3900 | ce_loss: 1.4104 | total_loss: 1.4104 | LR: 4.11e-05\n",
            "Epoch 5: 100%|██████████| 1563/1563 [22:25<00:00,  1.16it/s, loss=0.9782, lr=4.11e-05]\n",
            "INFO:src.training.trainer:\n",
            "Epoch 5 metrics:\n",
            "INFO:src.training.trainer:  loss: 1.2357\n",
            "INFO:src.training.trainer:  ce_loss: 1.2357\n",
            "INFO:src.training.trainer:\n",
            "======================================================================\n",
            "INFO:src.training.trainer:Epoch 6/7\n",
            "INFO:src.training.trainer:======================================================================\n",
            "Epoch 6:   6%|▌         | 89/1563 [01:18<21:05,  1.17it/s, loss=1.2009, lr=4.08e-05]INFO:src.training.trainer:Step 3950 | ce_loss: 1.2009 | total_loss: 1.2009 | LR: 4.08e-05\n",
            "Epoch 6:   6%|▌         | 90/1563 [01:18<21:11,  1.16it/s, loss=1.2981, lr=4.08e-05]INFO:src.training.trainer:Step 3950 | ce_loss: 1.2981 | total_loss: 1.2981 | LR: 4.08e-05\n",
            "Epoch 6:  12%|█▏        | 189/1563 [02:44<19:40,  1.16it/s, loss=0.9669, lr=4.05e-05]INFO:src.training.trainer:Step 4000 | ce_loss: 0.9669 | total_loss: 0.9669 | LR: 4.05e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:39,  1.57it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:31,  4.92it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  8.00it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.66it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.87it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:09, 14.62it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:09, 15.96it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.96it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.69it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.23it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.63it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.88it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.08it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.25it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.33it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.41it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.47it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.50it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.53it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.51it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.51it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.50it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:02<00:05, 19.52it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.55it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.59it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:05, 19.56it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.53it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.52it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.56it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.56it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.56it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.54it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.58it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.55it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.53it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.55it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.62it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:07<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.59it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.70it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 4000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1519\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-4000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-4000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Removing old checkpoint: ../experiments/baseline/checkpoint-1000\n",
            "Epoch 6:  12%|█▏        | 190/1563 [02:56<1:38:18,  4.30s/it, loss=1.2600, lr=4.05e-05]INFO:src.training.trainer:Step 4000 | ce_loss: 1.2600 | total_loss: 1.2600 | LR: 4.05e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:41,  1.54it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:31,  4.84it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.90it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.56it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.77it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:10, 14.54it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:09, 15.87it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.89it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.66it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.19it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.62it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.92it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.12it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.26it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.37it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.44it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.51it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.55it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.56it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.57it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.59it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:02<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.57it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.64it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.65it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.66it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.64it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.69it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.63it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.61it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.60it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.61it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.62it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.63it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.63it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.63it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.62it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.62it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.62it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.62it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.61it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.59it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:07<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.61it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.71it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 4000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1519\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-4000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-4000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "Epoch 6:  18%|█▊        | 289/1563 [04:31<18:13,  1.17it/s, loss=1.1565, lr=4.02e-05]  INFO:src.training.trainer:Step 4050 | ce_loss: 1.1565 | total_loss: 1.1565 | LR: 4.02e-05\n",
            "Epoch 6:  19%|█▊        | 290/1563 [04:32<18:18,  1.16it/s, loss=1.0595, lr=4.02e-05]INFO:src.training.trainer:Step 4050 | ce_loss: 1.0595 | total_loss: 1.0595 | LR: 4.02e-05\n",
            "Epoch 6:  25%|██▍       | 389/1563 [05:57<16:47,  1.16it/s, loss=1.1778, lr=3.98e-05]INFO:src.training.trainer:Step 4100 | ce_loss: 1.1778 | total_loss: 1.1778 | LR: 3.98e-05\n",
            "Epoch 6:  25%|██▍       | 390/1563 [05:58<16:52,  1.16it/s, loss=1.2375, lr=3.98e-05]INFO:src.training.trainer:Step 4100 | ce_loss: 1.2375 | total_loss: 1.2375 | LR: 3.98e-05\n",
            "Epoch 6:  31%|███▏      | 489/1563 [07:24<15:21,  1.17it/s, loss=1.2201, lr=3.95e-05]INFO:src.training.trainer:Step 4150 | ce_loss: 1.2201 | total_loss: 1.2201 | LR: 3.95e-05\n",
            "Epoch 6:  31%|███▏      | 490/1563 [07:24<15:26,  1.16it/s, loss=1.3662, lr=3.95e-05]INFO:src.training.trainer:Step 4150 | ce_loss: 1.3662 | total_loss: 1.3662 | LR: 3.95e-05\n",
            "Epoch 6:  38%|███▊      | 589/1563 [08:50<13:56,  1.16it/s, loss=1.0726, lr=3.92e-05]INFO:src.training.trainer:Step 4200 | ce_loss: 1.0726 | total_loss: 1.0726 | LR: 3.92e-05\n",
            "Epoch 6:  38%|███▊      | 590/1563 [08:50<13:59,  1.16it/s, loss=1.3431, lr=3.92e-05]INFO:src.training.trainer:Step 4200 | ce_loss: 1.3431 | total_loss: 1.3431 | LR: 3.92e-05\n",
            "Epoch 6:  44%|████▍     | 689/1563 [10:16<12:30,  1.16it/s, loss=1.4765, lr=3.88e-05]INFO:src.training.trainer:Step 4250 | ce_loss: 1.4765 | total_loss: 1.4765 | LR: 3.88e-05\n",
            "Epoch 6:  44%|████▍     | 690/1563 [10:17<12:33,  1.16it/s, loss=1.2011, lr=3.88e-05]INFO:src.training.trainer:Step 4250 | ce_loss: 1.2011 | total_loss: 1.2011 | LR: 3.88e-05\n",
            "Epoch 6:  50%|█████     | 789/1563 [11:42<11:04,  1.17it/s, loss=1.4897, lr=3.85e-05]INFO:src.training.trainer:Step 4300 | ce_loss: 1.4897 | total_loss: 1.4897 | LR: 3.85e-05\n",
            "Epoch 6:  51%|█████     | 790/1563 [11:43<11:07,  1.16it/s, loss=1.3090, lr=3.85e-05]INFO:src.training.trainer:Step 4300 | ce_loss: 1.3090 | total_loss: 1.3090 | LR: 3.85e-05\n",
            "Epoch 6:  57%|█████▋    | 889/1563 [13:08<09:38,  1.16it/s, loss=1.2071, lr=3.82e-05]INFO:src.training.trainer:Step 4350 | ce_loss: 1.2071 | total_loss: 1.2071 | LR: 3.82e-05\n",
            "Epoch 6:  57%|█████▋    | 890/1563 [13:09<09:41,  1.16it/s, loss=1.1614, lr=3.82e-05]INFO:src.training.trainer:Step 4350 | ce_loss: 1.1614 | total_loss: 1.1614 | LR: 3.82e-05\n",
            "Epoch 6:  63%|██████▎   | 989/1563 [14:34<08:12,  1.17it/s, loss=1.1372, lr=3.78e-05]INFO:src.training.trainer:Step 4400 | ce_loss: 1.1372 | total_loss: 1.1372 | LR: 3.78e-05\n",
            "Epoch 6:  63%|██████▎   | 990/1563 [14:35<08:14,  1.16it/s, loss=1.0283, lr=3.78e-05]INFO:src.training.trainer:Step 4400 | ce_loss: 1.0283 | total_loss: 1.0283 | LR: 3.78e-05\n",
            "Epoch 6:  70%|██████▉   | 1089/1563 [16:00<06:46,  1.16it/s, loss=1.2487, lr=3.75e-05]INFO:src.training.trainer:Step 4450 | ce_loss: 1.2487 | total_loss: 1.2487 | LR: 3.75e-05\n",
            "Epoch 6:  70%|██████▉   | 1090/1563 [16:01<06:48,  1.16it/s, loss=1.3674, lr=3.75e-05]INFO:src.training.trainer:Step 4450 | ce_loss: 1.3674 | total_loss: 1.3674 | LR: 3.75e-05\n",
            "Epoch 6:  76%|███████▌  | 1189/1563 [17:26<05:21,  1.16it/s, loss=1.3015, lr=3.71e-05]INFO:src.training.trainer:Step 4500 | ce_loss: 1.3015 | total_loss: 1.3015 | LR: 3.71e-05\n",
            "Epoch 6:  76%|███████▌  | 1190/1563 [17:27<05:22,  1.16it/s, loss=1.0297, lr=3.71e-05]INFO:src.training.trainer:Step 4500 | ce_loss: 1.0297 | total_loss: 1.0297 | LR: 3.71e-05\n",
            "Epoch 6:  82%|████████▏ | 1289/1563 [18:52<03:55,  1.16it/s, loss=1.2530, lr=3.68e-05]INFO:src.training.trainer:Step 4550 | ce_loss: 1.2530 | total_loss: 1.2530 | LR: 3.68e-05\n",
            "Epoch 6:  83%|████████▎ | 1290/1563 [18:53<03:55,  1.16it/s, loss=1.0779, lr=3.68e-05]INFO:src.training.trainer:Step 4550 | ce_loss: 1.0779 | total_loss: 1.0779 | LR: 3.68e-05\n",
            "Epoch 6:  89%|████████▉ | 1389/1563 [20:18<02:29,  1.17it/s, loss=1.0608, lr=3.64e-05]INFO:src.training.trainer:Step 4600 | ce_loss: 1.0608 | total_loss: 1.0608 | LR: 3.64e-05\n",
            "Epoch 6:  89%|████████▉ | 1390/1563 [20:19<02:29,  1.16it/s, loss=1.0851, lr=3.64e-05]INFO:src.training.trainer:Step 4600 | ce_loss: 1.0851 | total_loss: 1.0851 | LR: 3.64e-05\n",
            "Epoch 6:  95%|█████████▌| 1489/1563 [21:44<01:03,  1.16it/s, loss=1.4529, lr=3.61e-05]INFO:src.training.trainer:Step 4650 | ce_loss: 1.4529 | total_loss: 1.4529 | LR: 3.61e-05\n",
            "Epoch 6:  95%|█████████▌| 1490/1563 [21:45<01:03,  1.16it/s, loss=1.1703, lr=3.61e-05]INFO:src.training.trainer:Step 4650 | ce_loss: 1.1703 | total_loss: 1.1703 | LR: 3.61e-05\n",
            "Epoch 6: 100%|██████████| 1563/1563 [22:47<00:00,  1.14it/s, loss=1.2979, lr=3.58e-05]\n",
            "INFO:src.training.trainer:\n",
            "Epoch 6 metrics:\n",
            "INFO:src.training.trainer:  loss: 1.2154\n",
            "INFO:src.training.trainer:  ce_loss: 1.2154\n",
            "INFO:src.training.trainer:\n",
            "======================================================================\n",
            "INFO:src.training.trainer:Epoch 7/7\n",
            "INFO:src.training.trainer:======================================================================\n",
            "Epoch 7:   2%|▏         | 27/1563 [00:24<21:57,  1.17it/s, loss=1.0479, lr=3.57e-05]INFO:src.training.trainer:Step 4700 | ce_loss: 1.0479 | total_loss: 1.0479 | LR: 3.57e-05\n",
            "Epoch 7:   2%|▏         | 28/1563 [00:25<22:03,  1.16it/s, loss=1.0865, lr=3.57e-05]INFO:src.training.trainer:Step 4700 | ce_loss: 1.0865 | total_loss: 1.0865 | LR: 3.57e-05\n",
            "Epoch 7:   8%|▊         | 127/1563 [01:50<20:32,  1.17it/s, loss=1.2112, lr=3.53e-05]INFO:src.training.trainer:Step 4750 | ce_loss: 1.2112 | total_loss: 1.2112 | LR: 3.53e-05\n",
            "Epoch 7:   8%|▊         | 128/1563 [01:51<20:38,  1.16it/s, loss=1.1554, lr=3.53e-05]INFO:src.training.trainer:Step 4750 | ce_loss: 1.1554 | total_loss: 1.1554 | LR: 3.53e-05\n",
            "Epoch 7:  15%|█▍        | 227/1563 [03:16<19:06,  1.17it/s, loss=1.1172, lr=3.50e-05]INFO:src.training.trainer:Step 4800 | ce_loss: 1.1172 | total_loss: 1.1172 | LR: 3.50e-05\n",
            "Epoch 7:  15%|█▍        | 228/1563 [03:17<19:12,  1.16it/s, loss=1.0438, lr=3.50e-05]INFO:src.training.trainer:Step 4800 | ce_loss: 1.0438 | total_loss: 1.0438 | LR: 3.50e-05\n",
            "Epoch 7:  21%|██        | 327/1563 [04:42<17:40,  1.17it/s, loss=1.0876, lr=3.46e-05]INFO:src.training.trainer:Step 4850 | ce_loss: 1.0876 | total_loss: 1.0876 | LR: 3.46e-05\n",
            "Epoch 7:  21%|██        | 328/1563 [04:43<17:45,  1.16it/s, loss=1.2749, lr=3.46e-05]INFO:src.training.trainer:Step 4850 | ce_loss: 1.2749 | total_loss: 1.2749 | LR: 3.46e-05\n",
            "Epoch 7:  27%|██▋       | 427/1563 [06:08<16:15,  1.16it/s, loss=1.0999, lr=3.42e-05]INFO:src.training.trainer:Step 4900 | ce_loss: 1.0999 | total_loss: 1.0999 | LR: 3.42e-05\n",
            "Epoch 7:  27%|██▋       | 428/1563 [06:09<16:20,  1.16it/s, loss=1.1680, lr=3.42e-05]INFO:src.training.trainer:Step 4900 | ce_loss: 1.1680 | total_loss: 1.1680 | LR: 3.42e-05\n",
            "Epoch 7:  34%|███▎      | 527/1563 [07:35<14:49,  1.17it/s, loss=1.4412, lr=3.38e-05]INFO:src.training.trainer:Step 4950 | ce_loss: 1.4412 | total_loss: 1.4412 | LR: 3.38e-05\n",
            "Epoch 7:  34%|███▍      | 528/1563 [07:35<14:53,  1.16it/s, loss=1.2570, lr=3.38e-05]INFO:src.training.trainer:Step 4950 | ce_loss: 1.2570 | total_loss: 1.2570 | LR: 3.38e-05\n",
            "Epoch 7:  40%|████      | 627/1563 [09:01<13:23,  1.17it/s, loss=1.2247, lr=3.35e-05]INFO:src.training.trainer:Step 5000 | ce_loss: 1.2247 | total_loss: 1.2247 | LR: 3.35e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:40,  1.56it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:31,  4.87it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.93it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.60it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.81it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:10, 14.57it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:09, 15.91it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.92it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.66it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.19it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.58it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.86it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.09it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.21it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.30it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.39it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.46it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.49it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.50it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.53it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.55it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:02<00:05, 19.53it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.55it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.56it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:05, 19.58it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.60it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.60it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.53it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.53it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.56it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.56it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.55it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.54it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.59it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.59it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.57it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.59it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.60it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.56it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:08<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.53it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.53it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.54it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.72it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 5000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1430\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/best_model\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-5000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-5000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "INFO:src.training.trainer:Removing old checkpoint: ../experiments/baseline/checkpoint-2000\n",
            "Epoch 7:  40%|████      | 628/1563 [09:13<1:06:00,  4.24s/it, loss=1.2638, lr=3.35e-05]INFO:src.training.trainer:Step 5000 | ce_loss: 1.2638 | total_loss: 1.2638 | LR: 3.35e-05\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "\n",
            "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   1%|          | 1/157 [00:00<01:43,  1.51it/s]\u001b[A\n",
            "Evaluating:   2%|▏         | 3/157 [00:00<00:32,  4.77it/s]\u001b[A\n",
            "Evaluating:   3%|▎         | 5/157 [00:00<00:19,  7.82it/s]\u001b[A\n",
            "Evaluating:   4%|▍         | 7/157 [00:00<00:14, 10.49it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 9/157 [00:01<00:11, 12.72it/s]\u001b[A\n",
            "Evaluating:   7%|▋         | 11/157 [00:01<00:10, 14.50it/s]\u001b[A\n",
            "Evaluating:   8%|▊         | 13/157 [00:01<00:09, 15.85it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 15/157 [00:01<00:08, 16.88it/s]\u001b[A\n",
            "Evaluating:  11%|█         | 17/157 [00:01<00:07, 17.63it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 19/157 [00:01<00:07, 18.19it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 21/157 [00:01<00:07, 18.60it/s]\u001b[A\n",
            "Evaluating:  15%|█▍        | 23/157 [00:01<00:07, 18.90it/s]\u001b[A\n",
            "Evaluating:  16%|█▌        | 25/157 [00:01<00:06, 19.12it/s]\u001b[A\n",
            "Evaluating:  17%|█▋        | 27/157 [00:01<00:06, 19.27it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 29/157 [00:02<00:06, 19.37it/s]\u001b[A\n",
            "Evaluating:  20%|█▉        | 31/157 [00:02<00:06, 19.43it/s]\u001b[A\n",
            "Evaluating:  21%|██        | 33/157 [00:02<00:06, 19.48it/s]\u001b[A\n",
            "Evaluating:  22%|██▏       | 35/157 [00:02<00:06, 19.53it/s]\u001b[A\n",
            "Evaluating:  24%|██▎       | 37/157 [00:02<00:06, 19.59it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 39/157 [00:02<00:06, 19.61it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 41/157 [00:02<00:05, 19.60it/s]\u001b[A\n",
            "Evaluating:  27%|██▋       | 43/157 [00:02<00:05, 19.61it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 45/157 [00:02<00:05, 19.62it/s]\u001b[A\n",
            "Evaluating:  30%|██▉       | 47/157 [00:03<00:05, 19.63it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 49/157 [00:03<00:05, 19.63it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 51/157 [00:03<00:05, 19.62it/s]\u001b[A\n",
            "Evaluating:  34%|███▍      | 53/157 [00:03<00:05, 19.60it/s]\u001b[A\n",
            "Evaluating:  35%|███▌      | 55/157 [00:03<00:05, 19.60it/s]\u001b[A\n",
            "Evaluating:  36%|███▋      | 57/157 [00:03<00:05, 19.61it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 59/157 [00:03<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 61/157 [00:03<00:04, 19.62it/s]\u001b[A\n",
            "Evaluating:  40%|████      | 63/157 [00:03<00:04, 19.60it/s]\u001b[A\n",
            "Evaluating:  41%|████▏     | 65/157 [00:03<00:04, 19.64it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 67/157 [00:04<00:04, 19.61it/s]\u001b[A\n",
            "Evaluating:  44%|████▍     | 69/157 [00:04<00:04, 19.59it/s]\u001b[A\n",
            "Evaluating:  45%|████▌     | 71/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  46%|████▋     | 73/157 [00:04<00:04, 19.56it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 75/157 [00:04<00:04, 19.57it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 77/157 [00:04<00:04, 19.58it/s]\u001b[A\n",
            "Evaluating:  50%|█████     | 79/157 [00:04<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 81/157 [00:04<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  53%|█████▎    | 83/157 [00:04<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  54%|█████▍    | 85/157 [00:04<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 87/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 89/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  58%|█████▊    | 91/157 [00:05<00:03, 19.57it/s]\u001b[A\n",
            "Evaluating:  59%|█████▉    | 93/157 [00:05<00:03, 19.58it/s]\u001b[A\n",
            "Evaluating:  61%|██████    | 95/157 [00:05<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 97/157 [00:05<00:03, 19.59it/s]\u001b[A\n",
            "Evaluating:  63%|██████▎   | 99/157 [00:05<00:02, 19.59it/s]\u001b[A\n",
            "Evaluating:  64%|██████▍   | 101/157 [00:05<00:02, 19.58it/s]\u001b[A\n",
            "Evaluating:  66%|██████▌   | 103/157 [00:05<00:02, 19.55it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 105/157 [00:05<00:02, 19.52it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 107/157 [00:06<00:02, 19.51it/s]\u001b[A\n",
            "Evaluating:  69%|██████▉   | 109/157 [00:06<00:02, 19.50it/s]\u001b[A\n",
            "Evaluating:  71%|███████   | 111/157 [00:06<00:02, 19.49it/s]\u001b[A\n",
            "Evaluating:  72%|███████▏  | 113/157 [00:06<00:02, 19.49it/s]\u001b[A\n",
            "Evaluating:  73%|███████▎  | 115/157 [00:06<00:02, 19.54it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 117/157 [00:06<00:02, 19.56it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 119/157 [00:06<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  77%|███████▋  | 121/157 [00:06<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  78%|███████▊  | 123/157 [00:06<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  80%|███████▉  | 125/157 [00:06<00:01, 19.57it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 127/157 [00:07<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 129/157 [00:07<00:01, 19.56it/s]\u001b[A\n",
            "Evaluating:  83%|████████▎ | 131/157 [00:07<00:01, 19.55it/s]\u001b[A\n",
            "Evaluating:  85%|████████▍ | 133/157 [00:07<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 135/157 [00:07<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 137/157 [00:07<00:01, 19.58it/s]\u001b[A\n",
            "Evaluating:  89%|████████▊ | 139/157 [00:07<00:00, 19.59it/s]\u001b[A\n",
            "Evaluating:  90%|████████▉ | 141/157 [00:07<00:00, 19.59it/s]\u001b[A\n",
            "Evaluating:  91%|█████████ | 143/157 [00:07<00:00, 19.59it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 145/157 [00:08<00:00, 19.55it/s]\u001b[A\n",
            "Evaluating:  94%|█████████▎| 147/157 [00:08<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▍| 149/157 [00:08<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  96%|█████████▌| 151/157 [00:08<00:00, 19.58it/s]\u001b[A\n",
            "Evaluating:  97%|█████████▋| 153/157 [00:08<00:00, 19.60it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.74it/s]\u001b[A\n",
            "INFO:src.training.trainer:\n",
            "Evaluation at step 5000:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1430\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/checkpoint-5000\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/checkpoint-5000\n",
            "INFO:src.models.student:Model saved successfully\n",
            "Epoch 7:  47%|████▋     | 727/1563 [10:48<11:57,  1.17it/s, loss=1.1737, lr=3.31e-05]  INFO:src.training.trainer:Step 5050 | ce_loss: 1.1737 | total_loss: 1.1737 | LR: 3.31e-05\n",
            "Epoch 7:  47%|████▋     | 728/1563 [10:49<12:00,  1.16it/s, loss=1.0327, lr=3.31e-05]INFO:src.training.trainer:Step 5050 | ce_loss: 1.0327 | total_loss: 1.0327 | LR: 3.31e-05\n",
            "Epoch 7:  53%|█████▎    | 827/1563 [12:14<10:32,  1.16it/s, loss=1.0923, lr=3.27e-05]INFO:src.training.trainer:Step 5100 | ce_loss: 1.0923 | total_loss: 1.0923 | LR: 3.27e-05\n",
            "Epoch 7:  53%|█████▎    | 828/1563 [12:15<10:34,  1.16it/s, loss=1.1387, lr=3.27e-05]INFO:src.training.trainer:Step 5100 | ce_loss: 1.1387 | total_loss: 1.1387 | LR: 3.27e-05\n",
            "Epoch 7:  59%|█████▉    | 927/1563 [13:40<09:06,  1.16it/s, loss=1.2240, lr=3.23e-05]INFO:src.training.trainer:Step 5150 | ce_loss: 1.2240 | total_loss: 1.2240 | LR: 3.23e-05\n",
            "Epoch 7:  59%|█████▉    | 928/1563 [13:41<09:08,  1.16it/s, loss=1.1110, lr=3.23e-05]INFO:src.training.trainer:Step 5150 | ce_loss: 1.1110 | total_loss: 1.1110 | LR: 3.23e-05\n",
            "Epoch 7:  66%|██████▌   | 1027/1563 [15:06<07:39,  1.17it/s, loss=1.2901, lr=3.19e-05]INFO:src.training.trainer:Step 5200 | ce_loss: 1.2901 | total_loss: 1.2901 | LR: 3.19e-05\n",
            "Epoch 7:  66%|██████▌   | 1028/1563 [15:07<07:41,  1.16it/s, loss=1.3284, lr=3.19e-05]INFO:src.training.trainer:Step 5200 | ce_loss: 1.3284 | total_loss: 1.3284 | LR: 3.19e-05\n",
            "Epoch 7:  72%|███████▏  | 1127/1563 [16:32<06:14,  1.16it/s, loss=1.1551, lr=3.15e-05]INFO:src.training.trainer:Step 5250 | ce_loss: 1.1551 | total_loss: 1.1551 | LR: 3.15e-05\n",
            "Epoch 7:  72%|███████▏  | 1128/1563 [16:33<06:15,  1.16it/s, loss=1.0378, lr=3.15e-05]INFO:src.training.trainer:Step 5250 | ce_loss: 1.0378 | total_loss: 1.0378 | LR: 3.15e-05\n",
            "Epoch 7:  79%|███████▊  | 1227/1563 [17:58<04:48,  1.17it/s, loss=1.1938, lr=3.11e-05]INFO:src.training.trainer:Step 5300 | ce_loss: 1.1938 | total_loss: 1.1938 | LR: 3.11e-05\n",
            "Epoch 7:  79%|███████▊  | 1228/1563 [17:59<04:49,  1.16it/s, loss=1.2377, lr=3.11e-05]INFO:src.training.trainer:Step 5300 | ce_loss: 1.2377 | total_loss: 1.2377 | LR: 3.11e-05\n",
            "Epoch 7:  85%|████████▍ | 1327/1563 [19:25<03:22,  1.17it/s, loss=1.2465, lr=3.08e-05]INFO:src.training.trainer:Step 5350 | ce_loss: 1.2465 | total_loss: 1.2465 | LR: 3.08e-05\n",
            "Epoch 7:  85%|████████▍ | 1328/1563 [19:25<03:22,  1.16it/s, loss=1.3139, lr=3.08e-05]INFO:src.training.trainer:Step 5350 | ce_loss: 1.3139 | total_loss: 1.3139 | LR: 3.08e-05\n",
            "Epoch 7:  91%|█████████▏| 1427/1563 [20:51<01:56,  1.17it/s, loss=0.9848, lr=3.04e-05]INFO:src.training.trainer:Step 5400 | ce_loss: 0.9848 | total_loss: 0.9848 | LR: 3.04e-05\n",
            "Epoch 7:  91%|█████████▏| 1428/1563 [20:51<01:56,  1.16it/s, loss=1.2276, lr=3.04e-05]INFO:src.training.trainer:Step 5400 | ce_loss: 1.2276 | total_loss: 1.2276 | LR: 3.04e-05\n",
            "Epoch 7:  98%|█████████▊| 1527/1563 [22:17<00:30,  1.16it/s, loss=1.2141, lr=3.00e-05]INFO:src.training.trainer:Step 5450 | ce_loss: 1.2141 | total_loss: 1.2141 | LR: 3.00e-05\n",
            "Epoch 7:  98%|█████████▊| 1528/1563 [22:17<00:30,  1.16it/s, loss=0.9991, lr=3.00e-05]INFO:src.training.trainer:Step 5450 | ce_loss: 0.9991 | total_loss: 0.9991 | LR: 3.00e-05\n",
            "Epoch 7: 100%|██████████| 1563/1563 [22:47<00:00,  1.14it/s, loss=1.3421, lr=2.98e-05]\n",
            "INFO:src.training.trainer:\n",
            "Epoch 7 metrics:\n",
            "INFO:src.training.trainer:  loss: 1.1991\n",
            "INFO:src.training.trainer:  ce_loss: 1.1991\n",
            "INFO:src.training.trainer:\n",
            "======================================================================\n",
            "INFO:src.training.trainer:TRAINING COMPLETE\n",
            "INFO:src.training.trainer:======================================================================\n",
            "INFO:src.training.trainer:\n",
            "Running final evaluation...\n",
            "INFO:src.training.trainer:\n",
            "Running evaluation...\n",
            "Evaluating: 100%|██████████| 157/157 [00:08<00:00, 17.75it/s]\n",
            "INFO:src.training.trainer:\n",
            "Final evaluation metrics:\n",
            "INFO:src.training.trainer:  eval_loss: 1.1418\n",
            "INFO:src.training.trainer:Saving checkpoint to ../experiments/baseline/final_model\n",
            "INFO:src.models.student:Saving model to ../experiments/baseline/final_model\n",
            "INFO:src.models.student:Model saved successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Baseline training completed in 159.1 minutes\n",
            "✓ Average time per epoch: 1363.5s\n"
          ]
        }
      ],
      "source": [
        "# Train Baseline Model\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STARTING BASELINE TRAINING (NO DISTILLATION)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nStudent: {student_config.model_name}\")\n",
        "print(f\"Loss: {baseline_distill_config.ce_weight}·CE + {baseline_distill_config.distill_weight}·KL\")\n",
        "print(f\"Loss: CE only (standard supervised learning)\")\n",
        "print(f\"Teacher guidance: DISABLED\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Start training\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "history = trainer.train()\n",
        "\n",
        "# Measure training time\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nBaseline training completed in {training_time/60:.1f} minutes\")\n",
        "print(f\"Average time per epoch: {training_time / training_config.num_epochs:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ccbec09",
      "metadata": {},
      "source": [
        "## 7. Analyze Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5cdf4413",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "BASELINE TRAINING HISTORY\n",
            "======================================================================\n",
            "\n",
            "Train history (7 epochs):\n",
            "  Epoch 1: loss=1.6901\n",
            "  Epoch 2: loss=1.3688\n",
            "  Epoch 3: loss=1.3041\n",
            "  Epoch 4: loss=1.2646\n",
            "  Epoch 5: loss=1.2357\n",
            "  Epoch 6: loss=1.2154\n",
            "  Epoch 7: loss=1.1991\n",
            "\n",
            "Eval history (12 evaluations):\n",
            "  Eval 1: eval_loss=3.6817\n",
            "  Eval 2: eval_loss=1.2309\n",
            "  Eval 3: eval_loss=1.2309\n",
            "  Eval 4: eval_loss=1.1852\n",
            "  Eval 5: eval_loss=1.1852\n",
            "  ... and 7 more\n"
          ]
        }
      ],
      "source": [
        "# Display training history\n",
        "print(\"=\" * 70)\n",
        "print(\"BASELINE TRAINING HISTORY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "train_history = history['train_history']\n",
        "eval_history = history['eval_history']\n",
        "\n",
        "print(f\"\\nTrain history ({len(train_history)} epochs):\")\n",
        "for i, metrics in enumerate(train_history):\n",
        "    print(f\"  Epoch {i+1}: loss={metrics['loss']:.4f}\")\n",
        "\n",
        "print(f\"\\nEval history ({len(eval_history)} evaluations):\")\n",
        "for i, metrics in enumerate(eval_history[:5]):\n",
        "    print(f\"  Eval {i+1}: eval_loss={metrics['eval_loss']:.4f}\")\n",
        "if len(eval_history) > 5:\n",
        "    print(f\"  ... and {len(eval_history) - 5} more\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bccd8e3e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss reduction: 29.05%\n",
            "Initial loss: 1.6901\n",
            "Final loss: 1.1991\n"
          ]
        }
      ],
      "source": [
        "# Visualize training curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Training loss per epoch\n",
        "epochs = range(1, len(train_history) + 1)\n",
        "train_losses = [m['loss'] for m in train_history]\n",
        "\n",
        "axes[0].plot(epochs, train_losses, marker='o', linewidth=2, markersize=8, \n",
        "             color='#e74c3c', label='Train Loss (Baseline)')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Baseline Training Loss (β=0.0, No Distillation)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Evaluation loss over time\n",
        "if eval_history:\n",
        "    eval_steps = range(1, len(eval_history) + 1)\n",
        "    eval_losses = [m['eval_loss'] for m in eval_history]\n",
        "    \n",
        "    axes[1].plot(eval_steps, eval_losses, marker='s', linewidth=2, markersize=8,\n",
        "                 color='#3498db', label='Eval Loss (Baseline)')\n",
        "    axes[1].set_xlabel('Evaluation Step')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].set_title('Baseline Evaluation Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Baseline Training (No Knowledge Distillation)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print loss reduction\n",
        "if len(train_losses) > 1:\n",
        "    initial_loss = train_losses[0]\n",
        "    final_loss = train_losses[-1]\n",
        "    reduction = (initial_loss - final_loss) / initial_loss * 100\n",
        "    print(f\"\\nLoss reduction: {reduction:.2f}%\")\n",
        "    print(f\"Initial loss: {initial_loss:.4f}\")\n",
        "    print(f\"Final loss: {final_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169e4d14",
      "metadata": {},
      "source": [
        "## 8. Test Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f2fdff0e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TESTING GENERATION (BASELINE MODEL)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "SAMPLE 1\n",
            "======================================================================\n",
            "\n",
            "Input:\n",
            "nli premise: Two women are embracing while holding to go packages. hypothesis: The sisters are hugging goodbye while holding to go packages after just eating lunch.\n",
            "\n",
            "Ground Truth:\n",
            "neutral explanation: The to go packages may not be from lunch.\n",
            "\n",
            "Baseline Prediction:\n",
            "neutral explanation: Just because two women are embracing while holding to go packages does not mean they are sisters hugging goodbye.\n",
            "\n",
            "======================================================================\n",
            "SAMPLE 2\n",
            "======================================================================\n",
            "\n",
            "Input:\n",
            "nli premise: Two women are embracing while holding to go packages. hypothesis: Two woman are holding packages.\n",
            "\n",
            "Ground Truth:\n",
            "entailment explanation: Saying the two women are holding packages is a way to paraphrase that the packages they are holding are to go packages.\n",
            "\n",
            "Baseline Prediction:\n",
            "entailment explanation: Holding to go packages is a rephrasing of holding packages.\n",
            "\n",
            "======================================================================\n",
            "SAMPLE 3\n",
            "======================================================================\n",
            "\n",
            "Input:\n",
            "nli premise: Two women are embracing while holding to go packages. hypothesis: The men are fighting outside a deli.\n",
            "\n",
            "Ground Truth:\n",
            "contradiction explanation: In the first sentence there is an action of affection between women while on the second sentence there is a fight between men.\n",
            "\n",
            "Baseline Prediction:\n",
            "contradiction explanation: Women are not men.\n"
          ]
        }
      ],
      "source": [
        "# Test generation after baseline training\n",
        "print(\"=\" * 70)\n",
        "print(\"TESTING GENERATION (BASELINE MODEL)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "student.model.eval()\n",
        "\n",
        "# Get a batch from validation set\n",
        "val_batch = next(iter(val_loader))\n",
        "val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    generated_ids = student.generate(\n",
        "        input_ids=val_batch['input_ids'][:3],\n",
        "        attention_mask=val_batch['attention_mask'][:3],\n",
        "        max_length=64,\n",
        "        num_beams=4\n",
        "    )\n",
        "\n",
        "# Decode\n",
        "predictions = student.decode_batch(generated_ids)\n",
        "inputs = student.decode_batch(val_batch['input_ids'][:3])\n",
        "\n",
        "labels = val_batch['labels'][:3].clone()\n",
        "labels[labels == -100] = student.tokenizer.pad_token_id\n",
        "ground_truths = student.decode_batch(labels)\n",
        "\n",
        "# Display\n",
        "for i in range(3):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"SAMPLE {i+1}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"\\nInput:\\n{inputs[i]}\")\n",
        "    print(f\"\\nGround Truth:\\n{ground_truths[i]}\")\n",
        "    print(f\"\\nBaseline Prediction:\\n{predictions[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9373f987",
      "metadata": {},
      "source": [
        "## 9. Save Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111f3cb9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "SAVED BASELINE CHECKPOINTS\n",
            "======================================================================\n",
            "\n",
            "Found 6 items in output directory:\n",
            "- best_model (926.17 MB)\n",
            "- checkpoint-3000 (926.17 MB)\n",
            "- checkpoint-4000 (926.17 MB)\n",
            "- checkpoint-5000 (926.17 MB)\n",
            "- final_model (926.17 MB)\n",
            "- training_config.json\n"
          ]
        }
      ],
      "source": [
        "# Check saved checkpoints\n",
        "print(\"=\" * 70)\n",
        "print(\"SAVED BASELINE CHECKPOINTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "output_dir = Path(training_config.output_dir)\n",
        "\n",
        "if output_dir.exists():\n",
        "    checkpoints = list(output_dir.iterdir())\n",
        "    print(f\"\\nFound {len(checkpoints)} items in output directory:\")\n",
        "    for checkpoint in sorted(checkpoints):\n",
        "        if checkpoint.is_dir():\n",
        "            size = sum(f.stat().st_size for f in checkpoint.rglob('*') if f.is_file())\n",
        "            print(f\"- {checkpoint.name} ({size / 1e6:.2f} MB)\")\n",
        "        else:\n",
        "            print(f\"- {checkpoint.name}\")\n",
        "else:\n",
        "    print(\"\\nOutput directory not found!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
