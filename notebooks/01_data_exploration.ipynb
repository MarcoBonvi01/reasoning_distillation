{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration and Validation\n",
        "## Reasoning Distillation Project\n",
        "\n",
        "This notebook:\n",
        "1. Downloads e-SNLI and Alpaca datasets\n",
        "2. Validates data quality and structure\n",
        "3. Computes statistics\n",
        "4. Visualizes sample examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Imports\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pprint import pprint\n",
        "\n",
        "from src.data.data_loader import (\n",
        "    TeacherDataLoader,\n",
        "    DatasetConfig,\n",
        "    quick_load_esnli,\n",
        "    quick_load_alpaca\n",
        ")\n",
        "\n",
        "# Styling\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Initialize Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create configuration\n",
        "config = DatasetConfig(\n",
        "    raw_data_dir=\"../data/raw\",\n",
        "    processed_data_dir=\"../data/processed\",\n",
        "    cache_dir=\"../data/cache\"\n",
        ")\n",
        "\n",
        "# Initialize loader\n",
        "loader = TeacherDataLoader(config)\n",
        "print(\"Data loader initialized successfully!\")\n",
        "print(f\"Raw data directory: {config.raw_data_dir}\")\n",
        "print(f\"Cache directory: {config.cache_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Validate e-SNLI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load e-SNLI (all splits)\n",
        "print(\"Loading e-SNLI dataset...\")\n",
        "esnli_dataset = loader.load_esnli()\n",
        "\n",
        "# Display basic info\n",
        "print(f\"\\nAvailable splits: {list(esnli_dataset.keys())}\")\n",
        "for split_name, split_data in esnli_dataset.items():\n",
        "    print(f\"  {split_name}: {len(split_data):,} samples\")\n",
        "\n",
        "# Show features\n",
        "print(f\"\\nFeatures: {esnli_dataset['train'].features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate e-SNLI\n",
        "print(\"Validating e-SNLI dataset...\")\n",
        "esnli_stats = loader.validate_esnli(esnli_dataset)\n",
        "\n",
        "print(\"\\n=== e-SNLI Validation Statistics ===\")\n",
        "pprint(esnli_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize label distribution\n",
        "label_map = {0: 'Entailment', 1: 'Neutral', 2: 'Contradiction'}\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "for idx, (split_name, label_dist) in enumerate(esnli_stats['label_distribution'].items()):\n",
        "    labels = [label_map[k] for k in sorted(label_dist.keys())]\n",
        "    counts = [label_dist[k] for k in sorted(label_dist.keys())]\n",
        "    \n",
        "    axes[idx].bar(labels, counts, color=['#2ecc71', '#3498db', '#e74c3c'])\n",
        "    axes[idx].set_title(f'{split_name.capitalize()} Split')\n",
        "    axes[idx].set_ylabel('Count')\n",
        "    axes[idx].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.suptitle('e-SNLI Label Distribution', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize explanation lengths\n",
        "exp_stats = esnli_stats['explanation_stats']\n",
        "\n",
        "splits = list(exp_stats.keys())\n",
        "mean_lengths = [exp_stats[s]['mean_length'] for s in splits]\n",
        "min_lengths = [exp_stats[s]['min_length'] for s in splits]\n",
        "max_lengths = [exp_stats[s]['max_length'] for s in splits]\n",
        "\n",
        "x = range(len(splits))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar([i - width for i in x], mean_lengths, width, label='Mean', color='#3498db')\n",
        "plt.bar(x, min_lengths, width, label='Min', color='#2ecc71')\n",
        "plt.bar([i + width for i in x], max_lengths, width, label='Max', color='#e74c3c')\n",
        "\n",
        "plt.xlabel('Split')\n",
        "plt.ylabel('Explanation Length (words)')\n",
        "plt.title('e-SNLI Explanation Length Statistics')\n",
        "plt.xticks(x, splits)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample e-SNLI examples\n",
        "print(\"\\n=== Sample e-SNLI Examples ===\")\n",
        "samples = loader.get_sample_examples(esnli_dataset['train'], n_samples=3)\n",
        "\n",
        "for i, sample in enumerate(samples, 1):\n",
        "    parsed = loader.parse_esnli_sample(sample)\n",
        "    print(f\"\\n--- Example {i} ---\")\n",
        "    print(f\"Premise: {parsed['premise']}\")\n",
        "    print(f\"Hypothesis: {parsed['hypothesis']}\")\n",
        "    print(f\"Label: {label_map[parsed['label']]}\")\n",
        "    print(f\"Explanation: {parsed['explanation']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load and Validate Alpaca Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Alpaca (subset for quick testing)\n",
        "print(\"Loading Alpaca dataset...\")\n",
        "alpaca_dataset = loader.load_alpaca(\n",
        "    dataset_name=\"tatsu-lab/alpaca\",\n",
        "    max_samples=5000  # Use subset for faster testing\n",
        ")\n",
        "\n",
        "print(f\"\\nLoaded {len(alpaca_dataset):,} samples\")\n",
        "print(f\"Features: {alpaca_dataset.features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate Alpaca\n",
        "print(\"Validating Alpaca dataset...\")\n",
        "alpaca_stats = loader.validate_alpaca(alpaca_dataset)\n",
        "\n",
        "print(\"\\n=== Alpaca Validation Statistics ===\")\n",
        "pprint(alpaca_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Alpaca statistics\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Instruction vs Output lengths\n",
        "inst_stats = alpaca_stats['instruction_length']\n",
        "out_stats = alpaca_stats['output_length']\n",
        "\n",
        "categories = ['Mean', 'Min', 'Max']\n",
        "inst_values = [inst_stats['mean'], inst_stats['min'], inst_stats['max']]\n",
        "out_values = [out_stats['mean'], out_stats['min'], out_stats['max']]\n",
        "\n",
        "x = range(len(categories))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar([i - width/2 for i in x], inst_values, width, label='Instruction', color='#9b59b6')\n",
        "axes[0].bar([i + width/2 for i in x], out_values, width, label='Output', color='#e67e22')\n",
        "axes[0].set_ylabel('Length (words)')\n",
        "axes[0].set_title('Alpaca Text Length Statistics')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(categories)\n",
        "axes[0].legend()\n",
        "\n",
        "# Samples with/without input\n",
        "with_input = alpaca_stats['samples_with_input']\n",
        "without_input = alpaca_stats['total_samples'] - with_input\n",
        "\n",
        "axes[1].pie(\n",
        "    [with_input, without_input],\n",
        "    labels=['With Input Context', 'Without Input Context'],\n",
        "    autopct='%1.1f%%',\n",
        "    colors=['#3498db', '#95a5a6'],\n",
        "    startangle=90\n",
        ")\n",
        "axes[1].set_title('Alpaca Samples: Input Context Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample Alpaca examples\n",
        "print(\"\\n=== Sample Alpaca Examples ===\")\n",
        "alpaca_samples = loader.get_sample_examples(alpaca_dataset, n_samples=3)\n",
        "\n",
        "for i, sample in enumerate(alpaca_samples, 1):\n",
        "    parsed = loader.parse_alpaca_sample(sample)\n",
        "    print(f\"\\n--- Example {i} ---\")\n",
        "    print(f\"Instruction: {parsed['instruction']}\")\n",
        "    if parsed['input']:\n",
        "        print(f\"Input: {parsed['input']}\")\n",
        "    print(f\"Output: {parsed['output'][:200]}...\")  # Truncate long outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save Processed Data (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Save processed datasets for later use\n",
        "save_processed = False  # Set to True to save\n",
        "\n",
        "if save_processed:\n",
        "    print(\"Saving processed e-SNLI...\")\n",
        "    for split_name, split_data in esnli_dataset.items():\n",
        "        loader.save_processed_data(split_data, 'esnli', split_name)\n",
        "    \n",
        "    print(\"Saving processed Alpaca...\")\n",
        "    loader.save_processed_data(alpaca_dataset, 'alpaca', 'train')\n",
        "    \n",
        "    print(\"âœ“ All data saved successfully!\")\n",
        "else:\n",
        "    print(\"Skipping save step (set save_processed=True to save)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA LOADING & VALIDATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nðŸ“Š e-SNLI Dataset:\")\n",
        "for split_name in esnli_stats['splits']:\n",
        "    n = esnli_stats['splits'][split_name]\n",
        "    exp = esnli_stats['explanation_stats'][split_name]['samples_with_explanation']\n",
        "    print(f\"  â€¢ {split_name}: {n:,} samples ({exp:,} with explanations)\")\n",
        "\n",
        "print(\"\\nðŸ“š Alpaca Dataset:\")\n",
        "print(f\"  â€¢ Total samples: {alpaca_stats['total_samples']:,}\")\n",
        "print(f\"  â€¢ Mean instruction length: {alpaca_stats['instruction_length']['mean']:.1f} words\")\n",
        "print(f\"  â€¢ Mean output length: {alpaca_stats['output_length']['mean']:.1f} words\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
