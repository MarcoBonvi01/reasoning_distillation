{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop Testing Notebook\n",
    "## Reasoning Distillation Project\n",
    "\n",
    "This notebook tests:\n",
    "1. Distillation loss computation\n",
    "2. Trainer initialization\n",
    "3. Training loop (small scale)\n",
    "4. Evaluation pipeline\n",
    "5. Checkpointing and resuming\n",
    "6. Training history visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from src.data.data_loader import TeacherDataLoader\n",
    "from src.data.preprocessor import ReasoningPreprocessor, PreprocessConfig\n",
    "from src.data.dataset import ESNLIDataset, create_dataloaders\n",
    "\n",
    "from src.models.student import StudentModel, StudentConfig, create_student_model\n",
    "from src.models.teacher import DatasetTeacher\n",
    "\n",
    "from src.training.distillation import (\n",
    "    DistillationConfig,\n",
    "    SequenceLevelDistillation,\n",
    "    DistillationLoss,\n",
    "    compare_distillation_strategies\n",
    ")\n",
    "\n",
    "from src.training.trainer import (\n",
    "    Trainer,\n",
    "    TrainingConfig,\n",
    "    create_trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare Distillation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display strategy comparison\n",
    "compare_distillation_strategies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Distillation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize distillation loss\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING DISTILLATION LOSS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "distill_config = DistillationConfig(\n",
    "    ce_weight=1.0,\n",
    "    distill_weight=0.0,  # No explicit distillation for sequence-level\n",
    "    temperature=1.0,\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "loss_fn = DistillationLoss(distill_config)\n",
    "\n",
    "print(\"\\n‚úì DistillationLoss initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loss computation with dummy data\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPUTING LOSS ON DUMMY DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create dummy logits and labels\n",
    "batch_size = 4\n",
    "seq_len = 32\n",
    "vocab_size = 32128  # FLAN-T5 vocab size\n",
    "\n",
    "dummy_logits = torch.randn(batch_size, seq_len, vocab_size)\n",
    "dummy_labels = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "\n",
    "# Add some -100 (padding) labels\n",
    "dummy_labels[:, -5:] = -100\n",
    "\n",
    "print(f\"\\nLogits shape: {dummy_logits.shape}\")\n",
    "print(f\"Labels shape: {dummy_labels.shape}\")\n",
    "print(f\"Padding tokens: {(dummy_labels == -100).sum().item()}\")\n",
    "\n",
    "# Compute loss\n",
    "losses = loss_fn(dummy_logits, dummy_labels)\n",
    "\n",
    "print(\"\\nLoss components:\")\n",
    "for key, value in losses.items():\n",
    "    print(f\"  {key}: {value.item():.4f}\")\n",
    "\n",
    "# Test backward pass\n",
    "losses['total_loss'].backward()\n",
    "print(\"\\n‚úì Backward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Small Dataset for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load small dataset\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING TEST DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "loader = TeacherDataLoader()\n",
    "esnli_data = loader.load_esnli()\n",
    "\n",
    "# Use very small subsets for fast testing\n",
    "train_subset = esnli_data['train'].select(range(100))  # 100 samples\n",
    "val_subset = esnli_data['validation'].select(range(30))  # 30 samples\n",
    "\n",
    "print(f\"\\n‚úì Train samples: {len(train_subset)}\")\n",
    "print(f\"‚úì Val samples: {len(val_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "preprocess_config = PreprocessConfig(\n",
    "    model_name=\"google/flan-t5-small\",  # Use small for faster testing\n",
    "    max_source_length=128,\n",
    "    max_target_length=64\n",
    ")\n",
    "\n",
    "preprocessor = ReasoningPreprocessor(preprocess_config)\n",
    "\n",
    "train_dataset = ESNLIDataset(train_subset, preprocessor, use_cache=True)\n",
    "val_dataset = ESNLIDataset(val_subset, preprocessor, use_cache=True)\n",
    "\n",
    "# Create dataloaders with small batch size\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "    pad_token_id=preprocessor.tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Train batches: {len(train_loader)}\")\n",
    "print(f\"‚úì Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small student model for fast testing\n",
    "print(\"=\" * 70)\n",
    "print(\"INITIALIZING STUDENT MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "student_config = StudentConfig(\n",
    "    model_name=\"google/flan-t5-small\",\n",
    "    max_source_length=128,\n",
    "    max_target_length=64,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "student = StudentModel(student_config)\n",
    "\n",
    "print(f\"\\n‚úì Model loaded: {student.count_parameters():,} parameters\")\n",
    "print(f\"‚úì Memory: {student.get_memory_footprint()['total_mb']:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Distillation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequence-level distillation strategy\n",
    "print(\"=\" * 70)\n",
    "print(\"INITIALIZING DISTILLATION STRATEGY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "distill_config = DistillationConfig(\n",
    "    ce_weight=1.0,\n",
    "    distill_weight=0.0,  # Using dataset as teacher\n",
    "    label_smoothing=0.1,\n",
    "    distillation_type=\"sequence_level\"\n",
    ")\n",
    "\n",
    "distillation_strategy = SequenceLevelDistillation(distill_config)\n",
    "\n",
    "print(\"\\n‚úì SequenceLevelDistillation initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Single Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single training step manually\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING SINGLE TRAINING STEP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get a batch\n",
    "batch = next(iter(train_loader))\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "print(f\"\\nBatch shapes:\")\n",
    "for key, value in batch.items():\n",
    "    print(f\"  {key}: {value.shape}\")\n",
    "\n",
    "# Forward pass\n",
    "student.model.train()\n",
    "outputs = student(\n",
    "    input_ids=batch['input_ids'],\n",
    "    attention_mask=batch['attention_mask'],\n",
    "    labels=batch['labels']\n",
    ")\n",
    "\n",
    "# Compute distillation loss\n",
    "losses = distillation_strategy.compute_loss(\n",
    "    outputs['logits'],\n",
    "    batch['labels']\n",
    ")\n",
    "\n",
    "print(f\"\\nLoss values:\")\n",
    "for key, value in losses.items():\n",
    "    print(f\"  {key}: {value.item():.4f}\")\n",
    "\n",
    "# Backward pass\n",
    "loss = losses['total_loss']\n",
    "loss.backward()\n",
    "\n",
    "print(\"\\n‚úì Forward and backward pass successful!\")\n",
    "\n",
    "# Check gradients\n",
    "grad_norm = torch.nn.utils.clip_grad_norm_(student.model.parameters(), 1.0)\n",
    "print(f\"‚úì Gradient norm: {grad_norm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training configuration\n",
    "print(\"=\" * 70)\n",
    "print(\"INITIALIZING TRAINER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    num_epochs=2,  # Just 2 epochs for testing\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=10,\n",
    "    eval_steps=10,  # Evaluate frequently\n",
    "    save_steps=20,\n",
    "    logging_steps=5,\n",
    "    output_dir=\"../experiments/test_run\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    early_stopping_patience=5,\n",
    "    gradient_accumulation_steps=1,\n",
    "    max_grad_norm=1.0,\n",
    "    fp16=False  # Disable for testing\n",
    ")\n",
    "\n",
    "# Re-initialize model (previous one has gradients)\n",
    "student = StudentModel(student_config)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=student,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    distillation_strategy=distillation_strategy,\n",
    "    config=training_config\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Trainer initialized!\")\n",
    "print(f\"‚úì Total training steps: {len(train_loader) * training_config.num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = trainer.train()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úì Training completed in {training_time:.2f}s\")\n",
    "print(f\"‚úì Average time per epoch: {training_time / training_config.num_epochs:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyze Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training history\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING HISTORY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_history = history['train_history']\n",
    "eval_history = history['eval_history']\n",
    "\n",
    "print(f\"\\nTrain history ({len(train_history)} epochs):\")\n",
    "for i, metrics in enumerate(train_history):\n",
    "    print(f\"  Epoch {i+1}: loss={metrics['loss']:.4f}\")\n",
    "\n",
    "print(f\"\\nEval history ({len(eval_history)} evaluations):\")\n",
    "for i, metrics in enumerate(eval_history[:5]):  # Show first 5\n",
    "    print(f\"  Eval {i+1}: eval_loss={metrics['eval_loss']:.4f}\")\n",
    "if len(eval_history) > 5:\n",
    "    print(f\"  ... and {len(eval_history) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Training loss per epoch\n",
    "epochs = range(1, len(train_history) + 1)\n",
    "train_losses = [m['loss'] for m in train_history]\n",
    "\n",
    "axes[0].plot(epochs, train_losses, marker='o', linewidth=2, markersize=8, \n",
    "             color='#e74c3c', label='Train Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss per Epoch')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Evaluation loss over time\n",
    "if eval_history:\n",
    "    eval_steps = range(1, len(eval_history) + 1)\n",
    "    eval_losses = [m['eval_loss'] for m in eval_history]\n",
    "    \n",
    "    axes[1].plot(eval_steps, eval_losses, marker='s', linewidth=2, markersize=8,\n",
    "                 color='#3498db', label='Eval Loss')\n",
    "    axes[1].set_xlabel('Evaluation Step')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].set_title('Evaluation Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print loss reduction\n",
    "if len(train_losses) > 1:\n",
    "    initial_loss = train_losses[0]\n",
    "    final_loss = train_losses[-1]\n",
    "    reduction = (initial_loss - final_loss) / initial_loss * 100\n",
    "    print(f\"\\nLoss reduction: {reduction:.2f}%\")\n",
    "    print(f\"Initial loss: {initial_loss:.4f}\")\n",
    "    print(f\"Final loss: {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Model Generation After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generation on validation samples\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING GENERATION AFTER TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "student.model.eval()\n",
    "\n",
    "# Get a batch from validation set\n",
    "val_batch = next(iter(val_loader))\n",
    "val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    generated_ids = student.generate(\n",
    "        input_ids=val_batch['input_ids'][:3],  # First 3 samples\n",
    "        attention_mask=val_batch['attention_mask'][:3],\n",
    "        max_length=64,\n",
    "        num_beams=4\n",
    "    )\n",
    "\n",
    "# Decode\n",
    "predictions = student.decode_batch(generated_ids)\n",
    "inputs = student.decode_batch(val_batch['input_ids'][:3])\n",
    "\n",
    "labels = val_batch['labels'][:3].clone()\n",
    "labels[labels == -100] = student.tokenizer.pad_token_id\n",
    "ground_truths = student.decode_batch(labels)\n",
    "\n",
    "# Display\n",
    "for i in range(3):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SAMPLE {i+1}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nInput:\\n{inputs[i]}\")\n",
    "    print(f\"\\nGround Truth:\\n{ground_truths[i]}\")\n",
    "    print(f\"\\nPrediction:\\n{predictions[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test Checkpoint Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved checkpoints\n",
    "print(\"=\" * 70)\n",
    "print(\"CHECKING SAVED CHECKPOINTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "output_dir = Path(training_config.output_dir)\n",
    "\n",
    "if output_dir.exists():\n",
    "    checkpoints = list(output_dir.iterdir())\n",
    "    print(f\"\\nFound {len(checkpoints)} items in output directory:\")\n",
    "    for checkpoint in sorted(checkpoints):\n",
    "        if checkpoint.is_dir():\n",
    "            size = sum(f.stat().st_size for f in checkpoint.rglob('*') if f.is_file())\n",
    "            print(f\"  üìÅ {checkpoint.name} ({size / 1e6:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"  üìÑ {checkpoint.name}\")\n",
    "else:\n",
    "    print(\"\\nOutput directory not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading best model\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TESTING MODEL LOADING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_model_path = output_dir / \"best_model\"\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"\\nLoading best model from {best_model_path}...\")\n",
    "    \n",
    "    # Load model\n",
    "    loaded_student = StudentModel.load_model(\n",
    "        str(best_model_path),\n",
    "        config=student_config\n",
    "    )\n",
    "    \n",
    "    print(\"‚úì Model loaded successfully!\")\n",
    "    print(f\"‚úì Parameters: {loaded_student.count_parameters():,}\")\n",
    "    \n",
    "    # Test generation with loaded model\n",
    "    loaded_student.model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_gen = loaded_student.generate(\n",
    "            input_ids=val_batch['input_ids'][:1],\n",
    "            attention_mask=val_batch['attention_mask'][:1]\n",
    "        )\n",
    "    \n",
    "    test_pred = loaded_student.decode_batch(test_gen)[0]\n",
    "    print(f\"\\nTest generation: {test_pred[:100]}...\")\n",
    "    print(\"\\n‚úì Loaded model can generate!\")\n",
    "else:\n",
    "    print(\"\\nBest model not found (training might not have completed enough steps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test resuming from checkpoint\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING RESUME TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Find a checkpoint to resume from\n",
    "checkpoints = sorted(\n",
    "    [d for d in output_dir.iterdir() \n",
    "     if d.is_dir() and d.name.startswith(\"checkpoint-\")],\n",
    "    key=lambda x: int(x.name.split(\"-\")[1])\n",
    ")\n",
    "\n",
    "if checkpoints:\n",
    "    resume_checkpoint = checkpoints[-1]\n",
    "    print(f\"\\nResuming from: {resume_checkpoint.name}\")\n",
    "    \n",
    "    # Create new trainer and load checkpoint\n",
    "    resume_config = TrainingConfig(\n",
    "        num_epochs=3,  # Train 1 more epoch\n",
    "        learning_rate=5e-5,\n",
    "        warmup_steps=10,\n",
    "        eval_steps=10,\n",
    "        save_steps=20,\n",
    "        logging_steps=5,\n",
    "        output_dir=\"../experiments/test_run_resumed\",\n",
    "        eval_strategy=\"steps\"\n",
    "    )\n",
    "    \n",
    "    # Load model from checkpoint\n",
    "    resumed_student = StudentModel.load_model(\n",
    "        str(resume_checkpoint),\n",
    "        config=student_config\n",
    "    )\n",
    "    \n",
    "    resumed_trainer = Trainer(\n",
    "        model=resumed_student,\n",
    "        train_dataloader=train_loader,\n",
    "        eval_dataloader=val_loader,\n",
    "        distillation_strategy=distillation_strategy,\n",
    "        config=resume_config\n",
    "    )\n",
    "    \n",
    "    # Load training state\n",
    "    resumed_trainer.load_checkpoint(str(resume_checkpoint))\n",
    "    \n",
    "    print(f\"\\n‚úì Checkpoint loaded!\")\n",
    "    print(f\"  Resumed from step: {resumed_trainer.global_step}\")\n",
    "    print(f\"  Resumed from epoch: {resumed_trainer.epoch}\")\n",
    "    print(f\"  Best metric: {resumed_trainer.best_metric:.4f}\")\n",
    "    \n",
    "    print(\"\\nüí° Training state successfully restored!\")\n",
    "    print(\"   You can call resumed_trainer.train() to continue training.\")\n",
    "else:\n",
    "    print(\"\\nNo checkpoints found to resume from\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Analyze Optimizer State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze optimizer state\n",
    "print(\"=\" * 70)\n",
    "print(\"OPTIMIZER STATE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "optimizer_state = trainer.optimizer.state_dict()\n",
    "\n",
    "print(f\"\\nOptimizer: {type(trainer.optimizer).__name__}\")\n",
    "print(f\"\\nParameter groups: {len(optimizer_state['param_groups'])}\")\n",
    "\n",
    "for i, group in enumerate(optimizer_state['param_groups']):\n",
    "    print(f\"\\nGroup {i}:\")\n",
    "    print(f\"  Learning rate: {group['lr']:.2e}\")\n",
    "    print(f\"  Weight decay: {group['weight_decay']}\")\n",
    "    print(f\"  Parameters: {len(group['params'])}\")\n",
    "\n",
    "# Check learning rate schedule\n",
    "if trainer.scheduler:\n",
    "    current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "    print(f\"\\nCurrent learning rate: {current_lr:.2e}\")\n",
    "    print(f\"Initial learning rate: {training_config.learning_rate:.2e}\")\n",
    "    print(f\"LR change: {(current_lr / training_config.learning_rate - 1) * 100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Compare Before/After Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare loss before and after training\n",
    "print(\"=\" * 70)\n",
    "print(\"BEFORE/AFTER COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if eval_history:\n",
    "    initial_eval_loss = eval_history[0]['eval_loss']\n",
    "    final_eval_loss = eval_history[-1]['eval_loss']\n",
    "    \n",
    "    print(f\"\\nEvaluation Loss:\")\n",
    "    print(f\"  Initial: {initial_eval_loss:.4f}\")\n",
    "    print(f\"  Final: {final_eval_loss:.4f}\")\n",
    "    print(f\"  Improvement: {initial_eval_loss - final_eval_loss:.4f} ({(initial_eval_loss - final_eval_loss) / initial_eval_loss * 100:.2f}%)\")\n",
    "    \n",
    "    # Visualize improvement\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    losses = [initial_eval_loss, final_eval_loss]\n",
    "    labels = ['Before Training', 'After Training']\n",
    "    colors = ['#e74c3c', '#2ecc71']\n",
    "    \n",
    "    bars = ax.bar(labels, losses, color=colors, alpha=0.7, edgecolor='black', width=0.5)\n",
    "    ax.set_ylabel('Evaluation Loss')\n",
    "    ax.set_title('Model Performance: Before vs After Training')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, loss in zip(bars, losses):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{loss:.4f}',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add improvement annotation\n",
    "    improvement = initial_eval_loss - final_eval_loss\n",
    "    ax.annotate(\n",
    "        f'‚Üì {improvement:.4f}\\n({improvement/initial_eval_loss*100:.1f}% improvement)',\n",
    "        xy=(0.5, max(losses) * 0.5),\n",
    "        fontsize=14,\n",
    "        ha='center',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.3)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nNo evaluation history available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Test Different Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different label smoothing values\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING LABEL SMOOTHING IMPACT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "smoothing_values = [0.0, 0.1, 0.2]\n",
    "smoothing_results = []\n",
    "\n",
    "# Get a test batch\n",
    "test_batch = next(iter(train_loader))\n",
    "test_batch = {k: v.to(device) for k, v in test_batch.items()}\n",
    "\n",
    "for smoothing in smoothing_values:\n",
    "    # Create distillation with different smoothing\n",
    "    test_config = DistillationConfig(\n",
    "        ce_weight=1.0,\n",
    "        label_smoothing=smoothing\n",
    "    )\n",
    "    test_strategy = SequenceLevelDistillation(test_config)\n",
    "    \n",
    "    # Compute loss\n",
    "    student.model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = student(\n",
    "            input_ids=test_batch['input_ids'],\n",
    "            attention_mask=test_batch['attention_mask'],\n",
    "            labels=test_batch['labels']\n",
    "        )\n",
    "        losses = test_strategy.compute_loss(outputs['logits'], test_batch['labels'])\n",
    "    \n",
    "    smoothing_results.append({\n",
    "        'smoothing': smoothing,\n",
    "        'loss': losses['total_loss'].item()\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(\"\\nLabel Smoothing Impact on Loss:\")\n",
    "for result in smoothing_results:\n",
    "    print(f\"  Smoothing={result['smoothing']:.1f}: loss={result['loss']:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "smoothing_vals = [r['smoothing'] for r in smoothing_results]\n",
    "loss_vals = [r['loss'] for r in smoothing_results]\n",
    "\n",
    "ax.plot(smoothing_vals, loss_vals, marker='o', linewidth=2, markersize=10, color='#9b59b6')\n",
    "ax.set_xlabel('Label Smoothing')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Impact of Label Smoothing on Loss')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "for x, y in zip(smoothing_vals, loss_vals):\n",
    "    ax.text(x, y + 0.01, f'{y:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Memory and Speed Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile training step memory and speed\n",
    "print(\"=\" * 70)\n",
    "print(\"PROFILING TRAINING STEP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "student.model.train()\n",
    "\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    initial_memory = torch.cuda.memory_allocated() / 1e6\n",
    "\n",
    "# Time training step\n",
    "times = []\n",
    "for _ in range(5):\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Forward\n",
    "    outputs = student(\n",
    "        input_ids=batch['input_ids'],\n",
    "        attention_mask=batch['attention_mask'],\n",
    "        labels=batch['labels']\n",
    "    )\n",
    "    losses = distillation_strategy.compute_loss(outputs['logits'], batch['labels'])\n",
    "    loss = losses['total_loss']\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    \n",
    "    # Optimizer step\n",
    "    trainer.optimizer.step()\n",
    "    trainer.optimizer.zero_grad()\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    times.append(time.time() - start)\n",
    "\n",
    "avg_time = np.mean(times[1:])  # Skip first (warmup)\n",
    "std_time = np.std(times[1:])\n",
    "\n",
    "print(f\"\\nTraining Step Performance:\")\n",
    "print(f\"  Average time: {avg_time:.3f}s ¬± {std_time:.3f}s\")\n",
    "print(f\"  Throughput: {len(batch['input_ids']) / avg_time:.2f} samples/sec\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / 1e6\n",
    "    print(f\"\\nMemory Usage:\")\n",
    "    print(f\"  Initial: {initial_memory:.2f} MB\")\n",
    "    print(f\"  Peak: {peak_memory:.2f} MB\")\n",
    "    print(f\"  Overhead: {peak_memory - initial_memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING LOOP TESTING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n‚úÖ COMPONENTS TESTED:\")\n",
    "print(\"  ‚úì Distillation loss computation\")\n",
    "print(\"  ‚úì Single training step (forward + backward)\")\n",
    "print(\"  ‚úì Trainer initialization\")\n",
    "print(\"  ‚úì Full training loop (2 epochs)\")\n",
    "print(\"  ‚úì Evaluation pipeline\")\n",
    "print(\"  ‚úì Checkpointing (save/load)\")\n",
    "print(\"  ‚úì Resume training\")\n",
    "print(\"  ‚úì Optimizer state management\")\n",
    "print(\"  ‚úì Learning rate scheduling\")\n",
    "\n",
    "print(\"\\nüìä TRAINING RESULTS:\")\n",
    "print(f\"  ‚Ä¢ Training completed: {training_config.num_epochs} epochs\")\n",
    "print(f\"  ‚Ä¢ Total steps: {trainer.global_step}\")\n",
    "print(f\"  ‚Ä¢ Final train loss: {train_history[-1]['loss']:.4f}\")\n",
    "if eval_history:\n",
    "    print(f\"  ‚Ä¢ Final eval loss: {eval_history[-1]['eval_loss']:.4f}\")\n",
    "    improvement = (eval_history[0]['eval_loss'] - eval_history[-1]['eval_loss']) / eval_history[0]['eval_loss'] * 100\n",
    "    print(f\"  ‚Ä¢ Eval improvement: {improvement:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Training time: {training_time:.2f}s\")\n",
    "print(f\"  ‚Ä¢ Checkpoints saved: {len([d for d in output_dir.iterdir() if d.is_dir()])}\")\n",
    "\n",
    "print(\"\\n‚ö° PERFORMANCE:\")\n",
    "print(f\"  ‚Ä¢ Avg step time: {avg_time:.3f}s\")\n",
    "print(f\"  ‚Ä¢ Throughput: {len(batch['input_ids']) / avg_time:.2f} samples/sec\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"  ‚Ä¢ Peak GPU memory: {peak_memory:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ ALL TRAINING LOOP TESTS PASSED!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
